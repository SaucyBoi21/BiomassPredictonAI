---
title: "Model Selection"
author: "Jonathan CÃ¡rdenas"
date: "2023-03-12"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(dplyr)
library(readxl)
library(caret)
library(ggridges)
library(reshape2)
library(lubridate)
library(RColorBrewer)
library(corrplot)
library(GGally)
library(party)
library(MASS)
library(randomForest)
```
# 1. Dataset upload and data set splitting 
Uploading the original dataset (raw data): 
```{r}
raw_data<- read.csv("harvest_complete.csv")
raw_data$treatment <-as.factor(with(raw_data, ifelse(tray_id == '1', '280 ppm',
                                                     ifelse(tray_id == 2, '160 ppm', '80 ppm'))))
```

## 1.1 Separate dataset to use image derived features as predictors. 
Create 6 data frames based on the raw data: 
Source: Metadata, predictors and all response variables (raw_data).  
1) Image derived predictors and all response variables. 
2) Manual predictors and all response variables. 
3) Image derived predictors and LFW
4) Image derived predictors and LDW
5) Image derived predictors and LA

```{r}
img_predictors <- raw_data %>% dplyr::select(12:24) #1
manual_predictors <- raw_data %>% dplyr::select(1,3,7,9:12,25) #2
img_LFW <- raw_data %>% dplyr::select(7,12:24) #3
img_LDW <- raw_data %>% dplyr::select(8,12:24) #4
img_LA <- raw_data %>% dplyr::select(7,8,9,12:24) #5
```

# 2. Model Selection and Performance 

Fit different models to estimate 3 biomass variables (LFW,LDW,LA). Our baseline comparison (Model 0) will be a multiple linear regression model chose by using AIC and BIC criteria. 


## Model 0: Multiple Linear Regression. 
### Estimation of Leaf Fresh Weight (LFW)
```{r}
# Fitting null & full model to use step AIC in order to select the best variables (we want to optimize model fit and model complexity). 

full_LFW<- lm(LFW_g~., data = img_LFW)
null_LFW<- lm(LFW_g~1, data = img_LFW)

linear_mod<-stepAIC(null_LFW,direction = 'forward', scope = list(upper=full_LFW,lower = null_LFW))

# Here, we are storing the optimized linear model in a variable called linear_mod. 
```
```{r}
sum_linear<-summary(linear_mod)
sum_linear
```
After checking the coefficients p-value,looks like is possible to discard more predictors that are not so significant (plant_ellipse_minor_axis, plant_convex_hull_area). The model  shown here discards three variables that are not significant according to the coefficient p-value. However, our models performance gets worse. 
```{r}
opt_LFW_linear <- lm(LFW_g ~ height_mm + plant_area + 
    plant_ellipse_major_axis, 
    data = img_LFW)

summary(opt_LFW_linear)
```
### Fit a MLR but using a train and test set
```{r}
# Use a multiple linear regression model to predict LFW, this time splitting the dataset. 
set.seed(123)
train_id<- sample(1:nrow(img_LFW),0.7*nrow(img_LFW))
train_set<- img_LFW[train_id,]
test_set<- img_LFW[-train_id,]
```

```{r}
full_LFW_train<- lm(LFW_g~., data = train_set)
null_LFW_train<- lm(LFW_g~1, data = train_set)

linear_mod_train<-stepAIC(null_LFW_train,direction = 'forward', scope = list(upper=full_LFW_train,lower = null_LFW_train))

summary(linear_mod_train)
```

Now all the predictions will be made on our test set. Besides, the performance metrics and graphs displayed are based on the predictions obtain by our model in the test dataset.By doing this we are obtaining a realistic evaluation of our model. 

```{r}
MLR_pred <- predict(linear_mod_train, newdata = test_set)
```

The issue with the prediction is that we are fitting a global model that includes biomass quantification during previous days. This implies that we must run our prediction on datasets filtered by data to assess the model performance. 
```{r}
RMSE<-RMSE(MLR_pred,test_set$LFW_g) # using caret functions
R_sqrd<- R2(MLR_pred,test_set$LFW_g)
mean_LFW <- mean(test_set$LFW_g)
sd_LFW <- sd(test_set$LFW_g)

ggplot(data.frame(actual = test_set$LFW_g, predicted = MLR_pred), aes(x = actual, y = predicted)) + 
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Actual", y = "Predicted", title = "Multiple Linear Regression Prediction Accuracy")

# Print the performance metrics
cat("Average (LFW): ", mean_LFW, "\n")
cat("Standard deviation (LFW)): ", sd_LFW, "\n")
cat("R-squared: ", R_sqrd, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```
### Check model performance on different harvest dates: 

#### First Harvest Day: 
```{r}
LFW_harvest1 <- raw_data %>% filter(date == "02/02/2023") %>% dplyr::select(7,12:24) #3
```

```{r}
harvest1_pred <- predict(linear_mod_train, newdata = LFW_harvest1)
```

The issue with the prediction is that we are fitting a global model that includes biomass quantification during previous days. This implies that we must run our prediction on filtered data sets by date of  harvest to assess the model performance. 
```{r}
RMSE<-RMSE(harvest1_pred,LFW_harvest1$LFW_g) # using caret functions
R_sqrd<- R2(harvest1_pred,LFW_harvest1$LFW_g)
mean_LFW <- mean(LFW_harvest1$LFW_g)
sd_LFW <- sd(LFW_harvest1$LFW_g)

ggplot(data.frame(actual = LFW_harvest1$LFW_g, predicted = harvest1_pred), aes(x = actual, y = predicted)) + 
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Actual", y = "Predicted", title = "Multiple Linear Regression Prediction- Accuracy for First Harvest Day")

# Print the performance metrics
cat("Average (LFW): ", mean_LFW, "\n")
cat("Standard deviation (LFW)): ", sd_LFW, "\n")
cat("R-squared: ", R_sqrd, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```
The issue here is the number of individuals harvest on this date. Since we are using train and test datasets the amount of plants harvested on the first harvest is too short compared with the amount of plants harvested on the last day. A solution for this could be to set a min number of plants for each harvest date or in the next experiment, to collect same amount of information for each harvest. 
#### Second Harvest Day: 
```{r}
LFW_harvest2 <- raw_data %>% filter(date == "09/02/2023") %>% dplyr::select(7,12:24) #3
```

```{r}
harvest2_pred <- predict(linear_mod_train, newdata = LFW_harvest2)
```

The issue with the prediction is that we are fitting a global model that includes biomass quantification during previous days. This implies that we must run our prediction on filtered data sets by date of  harvest to assess the model performance. 
```{r}
RMSE<-RMSE(harvest2_pred,LFW_harvest2$LFW_g) # using caret functions
R_sqrd<- R2(harvest2_pred,LFW_harvest2$LFW_g)
mean_LFW <- mean(LFW_harvest2$LFW_g)
sd_LFW <- sd(LFW_harvest2$LFW_g)

ggplot(data.frame(actual = LFW_harvest2$LFW_g, predicted = harvest2_pred), aes(x = actual, y = predicted)) + 
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Actual", y = "Predicted", title = "Multiple Linear Regression Prediction- Accuracy for Second Harvest Day")

# Print the performance metrics
cat("Average (LFW): ", mean_LFW, "\n")
cat("Standard deviation (LFW)): ", sd_LFW, "\n")
cat("R-squared: ", R_sqrd, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```
#### Last Harvest Day:
```{r}
LFW_harvest3 <- raw_data %>% filter(date == "23/02/2023") %>% dplyr::select(7,12:24) #3
```

```{r}
harvest3_pred <- predict(linear_mod_train, newdata = LFW_harvest3)
```

The issue with the prediction is that we are fitting a global model that includes biomass quantification during previous days. This implies that we must run our prediction on filtered data sets by date of  harvest to assess the model performance. 

```{r}
RMSE<-RMSE(harvest3_pred,LFW_harvest3$LFW_g) # using caret functions
R_sqrd<- R2(harvest3_pred,LFW_harvest3$LFW_g)
mean_LFW <- mean(LFW_harvest3$LFW_g)
sd_LFW <- sd(LFW_harvest3$LFW_g)

ggplot(data.frame(actual = LFW_harvest3$LFW_g, predicted = harvest3_pred), aes(x = actual, y = predicted)) + 
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Actual", y = "Predicted", title = "Multiple Linear Regression Prediction- Accuracy for Last harvest Day")

# Print the performance metrics
cat("Average (LFW): ", mean_LFW, "\n")
cat("Standard deviation (LFW)): ", sd_LFW, "\n")
cat("R-squared: ", R_sqrd, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```
### Fit Multiple Linear Model Using Normalized Data: 
For normalization I'm using the standardization function from the package Bbmisc. With this I will make sure all predictors have the same weight. 
```{r}
library(BBmisc)
stand_bbmisc <- normalize(img_predictors, method = 'range', range = c(0,1))
# LFW as response variable and normalize image derived predictors. 
LFW_std<- stand_bbmisc %>%
  mutate(LFW_g = img_LFW$LFW_g)
```

Once again we will fit the model using a train and test proportion.
```{r}
set.seed(123)
train_id_std<- sample(1:nrow(LFW_std),0.7*nrow(LFW_std))
train_set_std<- LFW_std[train_id_std,]
test_set_std<- LFW_std[-train_id_std,]
```

```{r}
full_LFW_std_train<- lm(LFW_g~., data = train_set_std)
null_LFW_std_train<- lm(LFW_g~1, data = train_set_std)

linear_mod_train_std<-stepAIC(null_LFW_std_train,direction = 'forward', scope = list(upper=full_LFW_std_train,lower = null_LFW_std_train))

summary(linear_mod_train_std)
```


```{r}
MLR_pred_std <- predict(linear_mod_train_std, newdata = test_set_std)
```

The issue with the prediction is that we are fitting a global model that includes biomass quantification during previous days. This implies that we must run our prediction on datasets filtered by data to assess the model performance. 
```{r}
RMSE<-RMSE(MLR_pred_std,test_set_std$LFW_g) # using caret functions
R_sqrd<- R2(MLR_pred_std,test_set_std$LFW_g)
mean_LFW <- mean(test_set_std$LFW_g)
sd_LFW <- sd(test_set_std$LFW_g)

ggplot(data.frame(actual = test_set_std$LFW_g, predicted = MLR_pred_std), aes(x = actual, y = predicted)) + 
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Actual", y = "Predicted", title = "Multiple Linear Regression Prediction Accuracy Using Normalized Predictors")

# Print the performance metrics
cat("Average (LFW): ", mean_LFW, "\n")
cat("Standard deviation (LFW)): ", sd_LFW, "\n")
cat("R-squared: ", R_sqrd, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```
#### First Harvest Day: 
```{r}
LFW_harvest1_std <- raw_data %>% filter(date == "02/02/2023") %>% dplyr::select(7,12:24) #3
```

```{r}
harvest1_pred_std <- predict(linear_mod_train_std, newdata = LFW_harvest1_std)
```

The issue with the prediction is that we are fitting a global model that includes biomass quantification during previous days. This implies that we must run our prediction on filtered data sets by date of  harvest to assess the model performance. 
```{r}
RMSE<-RMSE(harvest1_pred_std,LFW_harvest1_std$LFW_g) # using caret functions
R_sqrd<- R2(harvest1_pred_std,LFW_harvest1_std$LFW_g)
mean_LFW <- mean(LFW_harvest1_std$LFW_g)
sd_LFW <- sd(LFW_harvest1_std$LFW_g)

ggplot(data.frame(actual = LFW_harvest1_std$LFW_g, predicted = harvest1_pred_std), aes(x = actual, y = predicted)) + 
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Actual", y = "Predicted", title = "Multiple Linear Regression Prediction- Accuracy for First Harvest Day")

# Print the performance metrics
cat("Average (LFW): ", mean_LFW, "\n")
cat("Standard deviation (LFW)): ", sd_LFW, "\n")
cat("R-squared: ", R_sqrd, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```
### Estimation of Leaf Dry Weight (LDW)
```{r}
# Fitting null & full model to use step AIC in order to select the best variables (we wabt to optimize model fit and model complexity). 

full_LDW<- lm(LDW_g~., data = img_LDW)
null_LDW<- lm(LDW_g~1, data = img_LDW)
linear_LDW<-stepAIC(null_LDW,direction = 'forward', scope = list(upper=full_LDW,lower = null_LDW))

# Here, we are storing the optimized linear model in a variable called linear_mod. 
```

```{r}
summary(linear_LDW)
```

### Estimation of Leaf Area (LA)
Notice that for Leaf Area(LA) we are including both LFW and LDW as predictors. 
```{r}
# Fitting null & full model to use step AIC in order to select the best variables (we wabt to optimize model fit and model complexity). 

full_LA<- lm(LA_mm2~., data = img_LA)
null_LA<- lm(LA_mm2~1, data = img_LA)
linear_LA<-stepAIC(null_LA,direction = 'forward', scope = list(upper=full_LA,lower = null_LA))

# Here, we are storing the optimized linear model in a variable called linear_mod. 
```

```{r}
summary(linear_LA)
```
