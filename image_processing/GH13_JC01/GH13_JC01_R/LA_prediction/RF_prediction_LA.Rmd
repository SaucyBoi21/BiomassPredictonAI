---
title: "Leaf Area Prediction using Random Forest"
author: "Jonathan CÃ¡rdenas"
date: "2023-04-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(BBmisc)
library(tidyverse)
library(dplyr)
library(readr)
library(caret)
library(ggridges)
library(reshape2)
library(lubridate)
library(RColorBrewer)
library(corrplot)
library(GGally)
library(party)
library(MASS)
library(randomForest)
```

```{r}
raw_data<- read.csv("harvest_complete.csv")
raw_data$treatment <-as.factor(with(raw_data, ifelse(tray_id == '1', '280 ppm',
                                                     ifelse(tray_id == 2, '160 ppm', '80 ppm'))))
raw_data <- raw_data %>% relocate(treatment)
raw_data$plant_volume <- raw_data$plant_area * raw_data$height_mm
```


Create 3 dataframes for predictors, response variable and combination of both
```{r}
# normalize img predictors
LA_predictors <- raw_data %>% dplyr::select(8,9,13:26) #1
predictors_norm <- normalize(LA_predictors, method = 'standardize')

# extract LA from raw data
LA_date<- raw_data %>% dplyr::select(c('LA_mm2','date'))

# combine normalized predictors and raw data. 
img_LA <- bind_cols(predictors_norm,LA_date)
```

Select a random sample of 33 entries for the last two harvest:
```{r}
set.seed(12)
harvest_1 <-img_LA %>% filter(date == '02/02/2023') 

harvest_2 <- img_LA %>% filter(date == '09/02/2023') %>% sample_n(33)

harvest_3 <-  img_LA %>% filter(date == '23/02/2023') %>% sample_n(33)

harvest_sample <- bind_rows(harvest_1,harvest_2,harvest_3) %>% dplyr::select(-date)
```

Select a representative number of features according to BIC analysis performed in the markdown for feature selection. Select the features using dplyr select. 
```{r}
# BIC  features
new_dataset <- harvest_sample %>%dplyr::select(LA_mm2,LFW_g,LDW_g,height_mm, plant_height,new_feature)
```
Separate data in train and test data: 
```{r}
# Use a random forest model to predict LFW, this time splitting the dataset. 
train_id<- sample(1:nrow(new_dataset),0.7*nrow(new_dataset))
train_set<- new_dataset[train_id,]
test_set<- new_dataset[-train_id,]
```
Fit random forest model:
The following chart shows the models summary. Is important to mention here that the models summary give us an out-of-bag MSE (for values used to train the model).

```{r}
RF_model <- randomForest(LA_mm2~., data = train_set, ntree = 500, importance= TRUE)
RF_model
```

```{r}
varImpPlot(RF_model, sort = TRUE, n.var = 4, main = "Variable Importance Plot")
```

From now on, we will use the test set to perform predictions and to calculate all the performance statistics. 
```{r}
RF_prediction <- predict(RF_model, newdata = test_set)
```
Notice that the R-squared value obtained below is not the same as the R-quared given by the model's summary. For this R-squared we are correlating the predicted values and the labels from the test set.

MSE displayed is not the same as the summary MSE neither. The MSE we are calculating here is mean squared error of the model's prediction on the testing data. This metric measures how well the model generalizes to new, unseen data. 

While the two MSE values are related, they are not the same. The out-of-bag MSE gives an estimate of the model's generalization performance based on the training data, while the MSE on the test set provides an actual measure of how well the model performs on new, unseen data. 
```{r}
# Evaluate the model performance: On new, unseen data. 
MAE <- mean(abs(RF_prediction - test_set$LA_mm2))
MSE <- mean((RF_prediction - test_set$LA_mm2)^2)
R_squared <- cor(RF_prediction,test_set$LA_mm2)^2
RMSE<- RMSE(RF_prediction,test_set$LA_mm2)

# Print the performance metrics
cat("Mean Absolute Error (MAE): ", MAE, "\n")
cat("Mean Squared Error (MSE): ", MSE, "\n")
cat("R-squared: ", R_squared, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```

```{r}
ggplot(data.frame(actual = test_set$LA_mm2, predicted = RF_prediction), aes(x = actual, y = predicted)) + 
  theme_bw()+
  geom_point(color = "black", fill = "red",shape = 21, size = 2, stroke = 1) +
  geom_abline(slope = 1, intercept = 0, color = "black", size =0.8) +
  theme_light() +
  theme(plot.title = element_text(size=16,hjust = 0.5, face="bold"),
        axis.text = element_text(size = 7,color="black"),
        axis.title.x = element_text(size=12,face="bold"),
        axis.title = element_text(size = 12, face="bold"),
        legend.position = "top",
        legend.background = element_rect(fill="white",
                                         size=1, linetype="solid", 
                                         colour ="black"),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 10,
                                    face = "bold"),
        strip.background = element_rect(color="black", fill="green4", 
                                        size=1.5, linetype="solid"),
        strip.text.x = element_text(
          size = 12, color = "white", face = "bold.italic"))+
  labs(x = "Actual LFW (g)", 
       y = "Predicted LFW (g)", 
       title = "Accuracy: Random Forest Regression Model") +
  annotate("text", x = 250, y = 1000, label = paste("R-squared: ", round(R_squared, 3), "\n", "RMSE: ", round(RMSE, 3)), size = 4, color = "black")
```
# 2)Fit a RF model using all predictors
Instead of using the BIC_ features dataset I'm using all the image derived features available. We can reuse the harvest sample dataframe that includes all the predictors and the response variable LFW. 

Again, we divide our new dataset, this time including all image derived predictors in train and test dataset.

```{r}
# Use a random forest model to predict LFW, this time splitting the dataset. 
seed<-123
set.seed(seed)
train_id_all<- sample(1:nrow(harvest_sample),0.7*nrow(harvest_sample))
train_set_all<- harvest_sample[train_id_all,]
test_set_all<- harvest_sample[-train_id_all,]
```

# Hyperparameter tuning

```{r}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(seed)
tunegrid <- expand.grid(.mtry=c(4:14))
rf_gridsearch <- train(LA_mm2~., data=train_set_all, method="rf", metric="RMSE", tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
plot(rf_gridsearch)
```
```{r}
set.seed(seed)
RF_model_all <- randomForest(LA_mm2~., data = train_set_all,mtry=10, ntree = 500, importance= TRUE)
RF_model_all
```

```{r}
RF_model_all$importance 

varImpPlot(RF_model_all, sort = TRUE, n.var = 13, main = "Variable Importance Plot")
```
```{r}
RF_prediction_all <- predict(RF_model_all, newdata = test_set_all)
```

```{r}
# Evaluate the model performance: On new, unseen data. 
MAE <- mean(abs(RF_prediction_all - test_set_all$LA_mm2))
MSE <- mean((RF_prediction_all - test_set_all$LA_mm2)^2)
R_squared <- cor(RF_prediction_all,test_set_all$LA_mm2)^2
RMSE<- RMSE(RF_prediction_all,test_set_all$LA_mm2)


# Print the performance metrics
cat("Mean Absolute Error (MAE): ", MAE, "\n")
cat("Mean Squared Error (MSE): ", MSE, "\n")
cat("R-squared: ", R_squared, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```

```{r}
ggplot(data.frame(actual = test_set_all$LA_mm2, predicted = RF_prediction_all), aes(x = actual, y = predicted)) + 
  geom_point(color = "black", fill = "blue",shape = 21, size = 3, stroke = 1) +
  geom_abline(slope = 1, intercept = 0, color = "black", size =0.8) +
  theme_light() +
  theme(plot.title = element_text(size=20,hjust = 0.5, face="bold"),
        axis.text = element_text(size = 10,color="black"),
        axis.title.x = element_text(size=16,face="bold"),
        axis.title = element_text(size = 16, face="bold"),
        legend.position = "top",
        legend.background = element_rect(fill="white",
                                         size=1, linetype="solid", 
                                         colour ="black"),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 10,
                                    face = "bold"),
        strip.background = element_rect(color="black", fill="green4", 
                                        size=1.5, linetype="solid"),
        strip.text.x = element_text(
          size = 12, color = "white", face = "bold.italic"))+
  labs(x = "Actual LA (mm2)", 
       y = "Predicted LA (mm2)", 
       title = "Accuracy: RF Regression Model Leaf Area",
       subtitle = "Model performance on test set (all harvest days) ") +
 annotate("text", x = 200, y = 1000, label = paste("R-squared: ", round(R_squared, 3), "\n", "RMSE: ", round(RMSE, 3)), size = 5, color = "black")
```
```{r}
RF_all_H3 <- predict(RF_model_all, newdata = harvest_3)
RF_all_H3
```
```{r}
# Evaluate the model performance: On new, unseen data. 
MAE <- mean(abs(RF_all_H3 - harvest_3$LA_mm2))
MSE <- mean((RF_all_H3 - harvest_3$LA_mm2)^2)
R_squared <- cor(RF_all_H3,harvest_3$LA_mm2)^2
RMSE<- RMSE(RF_all_H3,harvest_3$LA_mm2)
mean_LA<- mean(harvest_3$LA_mm2)

# Print the performance metrics
cat("Mean Absolute Error (MAE): ", MAE, "\n")
cat("Mean Squared Error (MSE): ", MSE, "\n")
cat("R-squared: ", R_squared, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
cat("Mean (LA): ", mean_LA, "\n")
```
```{r}
ggplot(data.frame(actual = harvest_3$LA_mm2, predicted = RF_all_H3), aes(x = actual, y = predicted)) + 
   geom_point(color = "black", fill = "blue3",shape = 21, size = 3, stroke = 1) +
  geom_abline(slope = 1, intercept = 0, color = "black", size =0.8) +
  theme_light() +
  theme(plot.title = element_text(size=20,hjust = 0.5, face="bold"),
        axis.text = element_text(size = 10,color="black"),
        axis.title.x = element_text(size=16,face="bold"),
        axis.title = element_text(size = 16, face="bold"),
        legend.position = "top",
        legend.background = element_rect(fill="white",
                                         size=1, linetype="solid", 
                                         colour ="black"),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 10,
                                    face = "bold"),
        strip.background = element_rect(color="black", fill="green4", 
                                        size=1.5, linetype="solid"),
        strip.text.x = element_text(
          size = 12, color = "white", face = "bold.italic"))+
  labs(x = "Actual LA (mm2)", 
       y = "Predicted LA (mm2)", 
       title = "Leaf Area (LA): 3rd Harvest Day") +
 annotate("text", x =1000, y = 1500, label = paste("R-squared: ", round(R_squared, 3), "\n", "RMSE: ", round(RMSE, 3),"\n","Mean Actual: ", round(mean_LA, 3),"mm2"), size = 5, color = "black")
ggsave("LA_figures/LA_3rdharvest.jpg",width = 7,height = 5,units = c("in"))
```
