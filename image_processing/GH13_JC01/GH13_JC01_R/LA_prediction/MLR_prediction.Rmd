---
title: "Leaf Area Prediction using Multiple Linear Regression"
author: "Jonathan CÃ¡rdenas"
date: "2023-04-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(BBmisc)
library(tidyverse)
library(dplyr)
library(readr)
library(caret)
library(ggridges)
library(reshape2)
library(lubridate)
library(RColorBrewer)
library(corrplot)
library(GGally)
library(party)
library(MASS)
library(randomForest)
```

```{r}
raw_data <- read.csv("harvest_complete.csv")
raw_data$treatment <-as.factor(with(raw_data, ifelse(tray_id == '1', '280 ppm',
                                                     ifelse(tray_id == 2, '160 ppm', '80 ppm'))))
```

Select a random sample of 33 entries for the last two harvest:
```{r}
set.seed(123)
harvest_1 <-raw_data %>% filter(date == '02/02/2023') 

harvest_2 <- raw_data %>% filter(date == '09/02/2023') %>% sample_n(33)

harvest_3 <-  raw_data %>% filter(date == '23/02/2023') %>% sample_n(33)

harvest_sample <- bind_rows(harvest_1,harvest_2,harvest_3)
```
Create 3 dataframes for predictors, response variable and combination of both
```{r}
img_predictors <- harvest_sample %>% dplyr::select(10:24) #1
LA<- harvest_sample %>% dplyr::select('LA_mm2')
img_LA <- harvest_sample %>% dplyr::select(7:9, 12:24) #3
```

Select a representative number of features according to BIC analysis performed in the markdown for feature selection
```{r}
BIC_features <-  img_LA %>% dplyr::select(LFW_g,LDW_g,height_mm, plant_height)
```
Data standarization:
```{r}
stand_bbmisc <- normalize(BIC_features, method = 'standardize')
new_dataset<- stand_bbmisc %>%
  mutate(LA_mm2 = LA$LA_mm2)
```

Separate data in train and test data: 
```{r}
# Use a random forest model to predict LFW, this time splitting the dataset. 
train_id<- sample(1:nrow(new_dataset),0.7*nrow(new_dataset))
train_set<- new_dataset[train_id,]
test_set<- new_dataset[-train_id,]
```
Fit random forest model:
The following chart shows the models summary. Is important to mention here that the models summary give us an out-of-bag MSE (for values used to train the model).

```{r}
MLR_model <- lm(LA_mm2~., data = train_set)
summary(MLR_model)
```

From now on, we will use the test set to perform predictions and to calculate all the performance statistics. 
```{r}
MLR_prediction <- predict(MLR_model, newdata = test_set)
```
Notice that the R-squared value obtained below is not the same as the R-quared given by the model's summary. For this R-squared we are correlating the predicted values and the labels from the test set.

MSE displayed is not the same as the summary MSE neither. The MSE we are calculating here is mean squared error of the model's prediction on the testing data. This metric measures how well the model generalizes to new, unseen data. 

While the two MSE values are related, they are not the same. The out-of-bag MSE gives an estimate of the model's generalization performance based on the training data, while the MSE on the test set provides an actual measure of how well the model performs on new, unseen data. 
```{r}
ggplot(data.frame(actual = test_set$LA_mm2, predicted = MLR_prediction), aes(x = actual, y = predicted)) + 
  theme_bw()+
  geom_point(color = "black", fill = "red",shape = 21, size = 2, stroke = 1) +
  geom_abline(slope = 1, intercept = 0, color = "black",linetype = "dashed") +
  labs(x = "Actual Leaf Area (mm2)", y = "Predicted Leaf Area (mm2)", title = "Accuracy: Multiple Linear Regression Model")
```
```{r}
# Evaluate the model performance: On new, unseen data. 
MAE <- mean(abs(MLR_prediction - test_set$LA_mm2))
MSE <- mean((MLR_prediction - test_set$LA_mm2)^2)
R_squared <- cor(MLR_prediction,test_set$LA_mm2)^2
RMSE<- RMSE(MLR_prediction,test_set$LA_mm2)

# Print the performance metrics
cat("Mean Absolute Error (MAE): ", MAE, "\n")
cat("Mean Squared Error (MSE): ", MSE, "\n")
cat("R-squared: ", R_squared, "\n")
cat("RMSE (Prediction): ", RMSE, "\n")
```
