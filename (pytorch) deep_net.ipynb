{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 150\n",
    "LOSS_FUNCTION = nn.MSELoss()\n",
    "LOWEST_LOSS = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_loss = {}\n",
    "y_loss['train'] = []\n",
    "y_loss['test'] = []\n",
    "\n",
    "X_epochs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_workflow(input_data, target_value):\n",
    "    X = input_data.drop([target_value], axis=1)\n",
    "    y = input_data[target_value]\n",
    "\n",
    "    #print(X)\n",
    "    #print(y)\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    X = torch.from_numpy(X)\n",
    "    y = torch.from_numpy(y)\n",
    "\n",
    "    data = TensorDataset(X, y)\n",
    "\n",
    "    train_ds, test_ds = train_test_split(data, test_size=0.2, random_state=25)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    print(f\"training data: {train_dl}\\n test data: {test_dl}\")\n",
    "    return train_dl, test_dl\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LFW_g</th>\n",
       "      <th>LDW_g</th>\n",
       "      <th>LA_mm2</th>\n",
       "      <th>length_mm</th>\n",
       "      <th>width_mm</th>\n",
       "      <th>height_mm</th>\n",
       "      <th>plant_area</th>\n",
       "      <th>plant_convex_hull_area</th>\n",
       "      <th>plant_solidity</th>\n",
       "      <th>plant_perimeter</th>\n",
       "      <th>plant_width</th>\n",
       "      <th>plant_height</th>\n",
       "      <th>plant_longest_path</th>\n",
       "      <th>plant_convex_hull_vertices</th>\n",
       "      <th>plant_ellipse_major_axis</th>\n",
       "      <th>plant_ellipse_minor_axis</th>\n",
       "      <th>plant_ellipse_angle</th>\n",
       "      <th>plant_ellipse_eccentricity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.30</td>\n",
       "      <td>0.078</td>\n",
       "      <td>31.95</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1211</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>0.831731</td>\n",
       "      <td>189.923880</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>346</td>\n",
       "      <td>16</td>\n",
       "      <td>45.684494</td>\n",
       "      <td>40.965988</td>\n",
       "      <td>92.878510</td>\n",
       "      <td>0.442608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.10</td>\n",
       "      <td>0.148</td>\n",
       "      <td>44.10</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1412</td>\n",
       "      <td>1556.5</td>\n",
       "      <td>0.907164</td>\n",
       "      <td>181.338094</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>370</td>\n",
       "      <td>20</td>\n",
       "      <td>53.368065</td>\n",
       "      <td>37.484673</td>\n",
       "      <td>96.255425</td>\n",
       "      <td>0.711802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.36</td>\n",
       "      <td>0.196</td>\n",
       "      <td>67.61</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1303</td>\n",
       "      <td>1766.5</td>\n",
       "      <td>0.737617</td>\n",
       "      <td>247.865005</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "      <td>333</td>\n",
       "      <td>19</td>\n",
       "      <td>46.356819</td>\n",
       "      <td>43.059174</td>\n",
       "      <td>2.102176</td>\n",
       "      <td>0.370421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.07</td>\n",
       "      <td>0.184</td>\n",
       "      <td>66.98</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1601</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>0.895915</td>\n",
       "      <td>203.480229</td>\n",
       "      <td>44</td>\n",
       "      <td>59</td>\n",
       "      <td>395</td>\n",
       "      <td>21</td>\n",
       "      <td>55.633369</td>\n",
       "      <td>38.548523</td>\n",
       "      <td>15.127802</td>\n",
       "      <td>0.721031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.17</td>\n",
       "      <td>0.187</td>\n",
       "      <td>68.74</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1919</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>0.809022</td>\n",
       "      <td>263.421354</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>454</td>\n",
       "      <td>19</td>\n",
       "      <td>60.012882</td>\n",
       "      <td>48.875011</td>\n",
       "      <td>55.774792</td>\n",
       "      <td>0.580292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>57.96</td>\n",
       "      <td>3.010</td>\n",
       "      <td>726.46</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19084</td>\n",
       "      <td>22974.0</td>\n",
       "      <td>0.830678</td>\n",
       "      <td>767.938160</td>\n",
       "      <td>193</td>\n",
       "      <td>167</td>\n",
       "      <td>1367</td>\n",
       "      <td>33</td>\n",
       "      <td>190.580887</td>\n",
       "      <td>137.733093</td>\n",
       "      <td>62.138748</td>\n",
       "      <td>0.691160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>81.46</td>\n",
       "      <td>3.880</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>18373</td>\n",
       "      <td>21556.5</td>\n",
       "      <td>0.852318</td>\n",
       "      <td>661.612260</td>\n",
       "      <td>164</td>\n",
       "      <td>189</td>\n",
       "      <td>1317</td>\n",
       "      <td>29</td>\n",
       "      <td>176.040924</td>\n",
       "      <td>141.141724</td>\n",
       "      <td>22.056726</td>\n",
       "      <td>0.597653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>140.84</td>\n",
       "      <td>6.380</td>\n",
       "      <td>1707.14</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>23374</td>\n",
       "      <td>26050.0</td>\n",
       "      <td>0.897274</td>\n",
       "      <td>683.754395</td>\n",
       "      <td>186</td>\n",
       "      <td>194</td>\n",
       "      <td>1427</td>\n",
       "      <td>31</td>\n",
       "      <td>191.379974</td>\n",
       "      <td>164.496170</td>\n",
       "      <td>175.959305</td>\n",
       "      <td>0.511091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>108.17</td>\n",
       "      <td>5.250</td>\n",
       "      <td>1364.18</td>\n",
       "      <td>31.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>23457</td>\n",
       "      <td>25678.5</td>\n",
       "      <td>0.913488</td>\n",
       "      <td>671.754395</td>\n",
       "      <td>198</td>\n",
       "      <td>179</td>\n",
       "      <td>1364</td>\n",
       "      <td>31</td>\n",
       "      <td>194.815384</td>\n",
       "      <td>159.870819</td>\n",
       "      <td>122.656914</td>\n",
       "      <td>0.571464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>64.40</td>\n",
       "      <td>3.350</td>\n",
       "      <td>812.24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>18533</td>\n",
       "      <td>22886.5</td>\n",
       "      <td>0.809779</td>\n",
       "      <td>821.595015</td>\n",
       "      <td>189</td>\n",
       "      <td>168</td>\n",
       "      <td>1376</td>\n",
       "      <td>22</td>\n",
       "      <td>193.579941</td>\n",
       "      <td>133.306320</td>\n",
       "      <td>123.732269</td>\n",
       "      <td>0.725106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LFW_g  LDW_g   LA_mm2  length_mm  width_mm  height_mm  plant_area  \\\n",
       "0      1.30  0.078    31.95        4.3       5.2        5.8        1211   \n",
       "1      2.10  0.148    44.10        5.3       5.7        5.5        1412   \n",
       "2      3.36  0.196    67.61        7.3       6.5        8.9        1303   \n",
       "3      3.07  0.184    66.98        5.8       7.6        7.5        1601   \n",
       "4      3.17  0.187    68.74        7.2       8.0        7.1        1919   \n",
       "..      ...    ...      ...        ...       ...        ...         ...   \n",
       "160   57.96  3.010   726.46       18.5      18.5       13.0       19084   \n",
       "161   81.46  3.880  1001.79       21.0      21.5       14.8       18373   \n",
       "162  140.84  6.380  1707.14       23.0      22.5       16.9       23374   \n",
       "163  108.17  5.250  1364.18       31.4      20.5       16.6       23457   \n",
       "164   64.40  3.350   812.24       21.0      18.0       14.7       18533   \n",
       "\n",
       "     plant_convex_hull_area  plant_solidity  plant_perimeter  plant_width  \\\n",
       "0                    1456.0        0.831731       189.923880           49   \n",
       "1                    1556.5        0.907164       181.338094           56   \n",
       "2                    1766.5        0.737617       247.865005           49   \n",
       "3                    1787.0        0.895915       203.480229           44   \n",
       "4                    2372.0        0.809022       263.421354           62   \n",
       "..                      ...             ...              ...          ...   \n",
       "160                 22974.0        0.830678       767.938160          193   \n",
       "161                 21556.5        0.852318       661.612260          164   \n",
       "162                 26050.0        0.897274       683.754395          186   \n",
       "163                 25678.5        0.913488       671.754395          198   \n",
       "164                 22886.5        0.809779       821.595015          189   \n",
       "\n",
       "     plant_height  plant_longest_path  plant_convex_hull_vertices  \\\n",
       "0              42                 346                          16   \n",
       "1              41                 370                          20   \n",
       "2              54                 333                          19   \n",
       "3              59                 395                          21   \n",
       "4              58                 454                          19   \n",
       "..            ...                 ...                         ...   \n",
       "160           167                1367                          33   \n",
       "161           189                1317                          29   \n",
       "162           194                1427                          31   \n",
       "163           179                1364                          31   \n",
       "164           168                1376                          22   \n",
       "\n",
       "     plant_ellipse_major_axis  plant_ellipse_minor_axis  plant_ellipse_angle  \\\n",
       "0                   45.684494                 40.965988            92.878510   \n",
       "1                   53.368065                 37.484673            96.255425   \n",
       "2                   46.356819                 43.059174             2.102176   \n",
       "3                   55.633369                 38.548523            15.127802   \n",
       "4                   60.012882                 48.875011            55.774792   \n",
       "..                        ...                       ...                  ...   \n",
       "160                190.580887                137.733093            62.138748   \n",
       "161                176.040924                141.141724            22.056726   \n",
       "162                191.379974                164.496170           175.959305   \n",
       "163                194.815384                159.870819           122.656914   \n",
       "164                193.579941                133.306320           123.732269   \n",
       "\n",
       "     plant_ellipse_eccentricity  \n",
       "0                      0.442608  \n",
       "1                      0.711802  \n",
       "2                      0.370421  \n",
       "3                      0.721031  \n",
       "4                      0.580292  \n",
       "..                          ...  \n",
       "160                    0.691160  \n",
       "161                    0.597653  \n",
       "162                    0.511091  \n",
       "163                    0.571464  \n",
       "164                    0.725106  \n",
       "\n",
       "[165 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_filepath = \"./final_harvest_data.csv\"\n",
    "\n",
    "data = pd.read_csv(csv_filepath)\n",
    "DATA = data.drop(['date', 'index', 'plant_id', 'tray_id', 'row', 'column'], axis=1)\n",
    "\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: <torch.utils.data.dataloader.DataLoader object at 0x7fa9e8cef5e0>\n",
      " test data: <torch.utils.data.dataloader.DataLoader object at 0x7fa9e8cef460>\n"
     ]
    }
   ],
   "source": [
    "LFW_train, LFW_test = data_workflow(DATA, 'LFW_g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_loss(current_best_val_loss, model_loss):\n",
    "    if current_best_val_loss > model_loss:\n",
    "        return model_loss\n",
    "    else:\n",
    "        return current_best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(17, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "            \n",
    "        ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits.double()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepNeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=17, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DeepNeuralNetwork()\n",
    "model = model.double()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataset, model, loss_function, optimizer, filler):\n",
    "    model.train()\n",
    "    for (X, y) in dataset:\n",
    "        #X, y = X.to('cuda'), y.to('cuda')\n",
    "        y = y.view(-1,1) \n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model(X)\n",
    "        loss = loss_function(prediction, y)\n",
    "\n",
    "        y_loss['train'].append(loss.item())\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        #print(f\"X: {X} \\n Y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataset, model, loss_function, optimizer, filler):\n",
    "    \n",
    "    for (X, y) in dataset:\n",
    "        #X, y = X.to('cuda'), y.to('cuda')\n",
    "        y = y.view(-1,1) \n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model(X)\n",
    "        loss = loss_function(prediction, y)\n",
    "\n",
    "        y_loss['test'].append(loss.item())\n",
    "        y_loss['test'].append(loss.item())\n",
    "        if (randint(0,100) < 50):\n",
    "            y_loss['test'].append(loss.item())\n",
    "\n",
    " \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global LOWEST_LOSS\n",
    "        \n",
    "        print(f\"Test Loss: {loss}\")\n",
    "        \n",
    "        #print(f\"X: {X} \\n Y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------------\n",
      "Test Loss: 47219.03845140395\n",
      "Test Loss: 58530.09549970959\n",
      "Epoch 2\n",
      "------------------------------------\n",
      "Test Loss: 656.9657147415878\n",
      "Test Loss: 2147.648390000756\n",
      "Epoch 3\n",
      "------------------------------------\n",
      "Test Loss: 9326.353843154282\n",
      "Test Loss: 10.004115874286246\n",
      "Epoch 4\n",
      "------------------------------------\n",
      "Test Loss: 366.3666968477167\n",
      "Test Loss: 677.6841364789597\n",
      "Epoch 5\n",
      "------------------------------------\n",
      "Test Loss: 999.1431609922336\n",
      "Test Loss: 190.5218345805909\n",
      "Epoch 6\n",
      "------------------------------------\n",
      "Test Loss: 249.26569590732828\n",
      "Test Loss: 0.8085237407637934\n",
      "Epoch 7\n",
      "------------------------------------\n",
      "Test Loss: 191.50723072188882\n",
      "Test Loss: 47.61204214012299\n",
      "Epoch 8\n",
      "------------------------------------\n",
      "Test Loss: 329.64120338968013\n",
      "Test Loss: 1206.826511321802\n",
      "Epoch 9\n",
      "------------------------------------\n",
      "Test Loss: 166.4840676425739\n",
      "Test Loss: 64.82003197089956\n",
      "Epoch 10\n",
      "------------------------------------\n",
      "Test Loss: 238.0647541925706\n",
      "Test Loss: 204.71305242846898\n",
      "Epoch 11\n",
      "------------------------------------\n",
      "Test Loss: 158.80676475152504\n",
      "Test Loss: 205.6160704536988\n",
      "Epoch 12\n",
      "------------------------------------\n",
      "Test Loss: 171.04117785743603\n",
      "Test Loss: 9.650014904670424\n",
      "Epoch 13\n",
      "------------------------------------\n",
      "Test Loss: 169.33477966866016\n",
      "Test Loss: 9.90136906042539\n",
      "Epoch 14\n",
      "------------------------------------\n",
      "Test Loss: 201.2100860042916\n",
      "Test Loss: 178.91678616907237\n",
      "Epoch 15\n",
      "------------------------------------\n",
      "Test Loss: 149.47497341726177\n",
      "Test Loss: 42.91351406624367\n",
      "Epoch 16\n",
      "------------------------------------\n",
      "Test Loss: 135.0329969783761\n",
      "Test Loss: 123.34798467136422\n",
      "Epoch 17\n",
      "------------------------------------\n",
      "Test Loss: 403.9839803892425\n",
      "Test Loss: 0.6117447307433492\n",
      "Epoch 18\n",
      "------------------------------------\n",
      "Test Loss: 181.24880410064281\n",
      "Test Loss: 320.05180612362625\n",
      "Epoch 19\n",
      "------------------------------------\n",
      "Test Loss: 492.4695383728582\n",
      "Test Loss: 3.5960041881128237\n",
      "Epoch 20\n",
      "------------------------------------\n",
      "Test Loss: 139.2129457479499\n",
      "Test Loss: 670.1753985963877\n",
      "Epoch 21\n",
      "------------------------------------\n",
      "Test Loss: 214.0020077554357\n",
      "Test Loss: 246.10987827995066\n",
      "Epoch 22\n",
      "------------------------------------\n",
      "Test Loss: 141.08331559610315\n",
      "Test Loss: 1.0173008498119114\n",
      "Epoch 23\n",
      "------------------------------------\n",
      "Test Loss: 177.08748116093247\n",
      "Test Loss: 104.62391181514636\n",
      "Epoch 24\n",
      "------------------------------------\n",
      "Test Loss: 115.82579157020183\n",
      "Test Loss: 567.8303640986354\n",
      "Epoch 25\n",
      "------------------------------------\n",
      "Test Loss: 207.67554390510196\n",
      "Test Loss: 55.803259275296725\n",
      "Epoch 26\n",
      "------------------------------------\n",
      "Test Loss: 126.25575421393735\n",
      "Test Loss: 6.921561862403179\n",
      "Epoch 27\n",
      "------------------------------------\n",
      "Test Loss: 334.7324154580453\n",
      "Test Loss: 163.71283289977262\n",
      "Epoch 28\n",
      "------------------------------------\n",
      "Test Loss: 105.02233317959988\n",
      "Test Loss: 336.71425386383305\n",
      "Epoch 29\n",
      "------------------------------------\n",
      "Test Loss: 198.75801838541605\n",
      "Test Loss: 64.19902733306783\n",
      "Epoch 30\n",
      "------------------------------------\n",
      "Test Loss: 188.92503906932347\n",
      "Test Loss: 15.532614460550397\n",
      "Epoch 31\n",
      "------------------------------------\n",
      "Test Loss: 123.90847015371884\n",
      "Test Loss: 2.8798616485803246\n",
      "Epoch 32\n",
      "------------------------------------\n",
      "Test Loss: 175.99745191747377\n",
      "Test Loss: 4.542251644328006\n",
      "Epoch 33\n",
      "------------------------------------\n",
      "Test Loss: 125.2377805325041\n",
      "Test Loss: 20.93104297973674\n",
      "Epoch 34\n",
      "------------------------------------\n",
      "Test Loss: 158.61489131526648\n",
      "Test Loss: 0.4633749579378477\n",
      "Epoch 35\n",
      "------------------------------------\n",
      "Test Loss: 116.81151357232189\n",
      "Test Loss: 100.74478871383027\n",
      "Epoch 36\n",
      "------------------------------------\n",
      "Test Loss: 121.45050760533775\n",
      "Test Loss: 648.5763747284875\n",
      "Epoch 37\n",
      "------------------------------------\n",
      "Test Loss: 119.53088326618429\n",
      "Test Loss: 58.36103445466402\n",
      "Epoch 38\n",
      "------------------------------------\n",
      "Test Loss: 154.88682010019022\n",
      "Test Loss: 231.5606234407585\n",
      "Epoch 39\n",
      "------------------------------------\n",
      "Test Loss: 118.11374449815075\n",
      "Test Loss: 12.485326698232853\n",
      "Epoch 40\n",
      "------------------------------------\n",
      "Test Loss: 136.32010305555525\n",
      "Test Loss: 51.32710384661829\n",
      "Epoch 41\n",
      "------------------------------------\n",
      "Test Loss: 124.31644082909759\n",
      "Test Loss: 64.21861493655551\n",
      "Epoch 42\n",
      "------------------------------------\n",
      "Test Loss: 137.47495758169202\n",
      "Test Loss: 0.13465724845845747\n",
      "Epoch 43\n",
      "------------------------------------\n",
      "Test Loss: 121.62607667100731\n",
      "Test Loss: 132.24084096248956\n",
      "Epoch 44\n",
      "------------------------------------\n",
      "Test Loss: 226.49075457101208\n",
      "Test Loss: 0.011372346264505048\n",
      "Epoch 45\n",
      "------------------------------------\n",
      "Test Loss: 144.45364059098634\n",
      "Test Loss: 6.407753672069648\n",
      "Epoch 46\n",
      "------------------------------------\n",
      "Test Loss: 211.47613997571537\n",
      "Test Loss: 34.342152694933354\n",
      "Epoch 47\n",
      "------------------------------------\n",
      "Test Loss: 130.74467235252604\n",
      "Test Loss: 0.6903075817890035\n",
      "Epoch 48\n",
      "------------------------------------\n",
      "Test Loss: 217.05369237663234\n",
      "Test Loss: 15.963677081460423\n",
      "Epoch 49\n",
      "------------------------------------\n",
      "Test Loss: 134.92887027167603\n",
      "Test Loss: 63.60256711765533\n",
      "Epoch 50\n",
      "------------------------------------\n",
      "Test Loss: 191.29456995228702\n",
      "Test Loss: 0.908020362650411\n",
      "Epoch 51\n",
      "------------------------------------\n",
      "Test Loss: 126.18091878276911\n",
      "Test Loss: 0.45898032326306354\n",
      "Epoch 52\n",
      "------------------------------------\n",
      "Test Loss: 129.0676024757507\n",
      "Test Loss: 0.6310415121645864\n",
      "Epoch 53\n",
      "------------------------------------\n",
      "Test Loss: 123.03687322061086\n",
      "Test Loss: 1.8585390590995403\n",
      "Epoch 54\n",
      "------------------------------------\n",
      "Test Loss: 122.18450541301837\n",
      "Test Loss: 3.578276132095902\n",
      "Epoch 55\n",
      "------------------------------------\n",
      "Test Loss: 280.1262640588891\n",
      "Test Loss: 0.10191939357545882\n",
      "Epoch 56\n",
      "------------------------------------\n",
      "Test Loss: 188.8516710921893\n",
      "Test Loss: 1.5952961551615203\n",
      "Epoch 57\n",
      "------------------------------------\n",
      "Test Loss: 192.34895638487632\n",
      "Test Loss: 12.897342044238655\n",
      "Epoch 58\n",
      "------------------------------------\n",
      "Test Loss: 159.52880994513578\n",
      "Test Loss: 2381.1443224859017\n",
      "Epoch 59\n",
      "------------------------------------\n",
      "Test Loss: 231.32696582137507\n",
      "Test Loss: 141.37700156010644\n",
      "Epoch 60\n",
      "------------------------------------\n",
      "Test Loss: 106.92640245692274\n",
      "Test Loss: 180.2777505448876\n",
      "Epoch 61\n",
      "------------------------------------\n",
      "Test Loss: 146.84640009653472\n",
      "Test Loss: 4.957718582555727\n",
      "Epoch 62\n",
      "------------------------------------\n",
      "Test Loss: 100.51457859645565\n",
      "Test Loss: 847.0578816899778\n",
      "Epoch 63\n",
      "------------------------------------\n",
      "Test Loss: 102.50896894213797\n",
      "Test Loss: 94.4043517673601\n",
      "Epoch 64\n",
      "------------------------------------\n",
      "Test Loss: 366.75471625758723\n",
      "Test Loss: 0.01650517336869013\n",
      "Epoch 65\n",
      "------------------------------------\n",
      "Test Loss: 147.78093033248155\n",
      "Test Loss: 219.00665505034152\n",
      "Epoch 66\n",
      "------------------------------------\n",
      "Test Loss: 296.0225340444957\n",
      "Test Loss: 0.5720046088171009\n",
      "Epoch 67\n",
      "------------------------------------\n",
      "Test Loss: 118.38486731723415\n",
      "Test Loss: 5.451182054955682\n",
      "Epoch 68\n",
      "------------------------------------\n",
      "Test Loss: 104.52128194366881\n",
      "Test Loss: 11.195095706198794\n",
      "Epoch 69\n",
      "------------------------------------\n",
      "Test Loss: 185.36517829388504\n",
      "Test Loss: 42.12169696370047\n",
      "Epoch 70\n",
      "------------------------------------\n",
      "Test Loss: 152.1108699612126\n",
      "Test Loss: 1.6529948035334878\n",
      "Epoch 71\n",
      "------------------------------------\n",
      "Test Loss: 281.7728160274181\n",
      "Test Loss: 0.5202918373128479\n",
      "Epoch 72\n",
      "------------------------------------\n",
      "Test Loss: 124.99440240824246\n",
      "Test Loss: 57.003873452109175\n",
      "Epoch 73\n",
      "------------------------------------\n",
      "Test Loss: 209.23805902521136\n",
      "Test Loss: 1728.6552827278867\n",
      "Epoch 74\n",
      "------------------------------------\n",
      "Test Loss: 85.49707087017052\n",
      "Test Loss: 40.78788910603214\n",
      "Epoch 75\n",
      "------------------------------------\n",
      "Test Loss: 152.34003777589686\n",
      "Test Loss: 27.97467943645398\n",
      "Epoch 76\n",
      "------------------------------------\n",
      "Test Loss: 294.9340110705508\n",
      "Test Loss: 1.8476996379546562\n",
      "Epoch 77\n",
      "------------------------------------\n",
      "Test Loss: 189.77108603014372\n",
      "Test Loss: 609.6506183151462\n",
      "Epoch 78\n",
      "------------------------------------\n",
      "Test Loss: 345.56016883121254\n",
      "Test Loss: 605.5871600292281\n",
      "Epoch 79\n",
      "------------------------------------\n",
      "Test Loss: 194.5036169238926\n",
      "Test Loss: 73.04975654493528\n",
      "Epoch 80\n",
      "------------------------------------\n",
      "Test Loss: 220.12300477034387\n",
      "Test Loss: 12.212659760870977\n",
      "Epoch 81\n",
      "------------------------------------\n",
      "Test Loss: 116.89087482753538\n",
      "Test Loss: 153.33537535408257\n",
      "Epoch 82\n",
      "------------------------------------\n",
      "Test Loss: 109.95367203060657\n",
      "Test Loss: 19.31468113150106\n",
      "Epoch 83\n",
      "------------------------------------\n",
      "Test Loss: 108.0943832629737\n",
      "Test Loss: 3.088382805017162\n",
      "Epoch 84\n",
      "------------------------------------\n",
      "Test Loss: 109.09573220884815\n",
      "Test Loss: 0.6526916113217148\n",
      "Epoch 85\n",
      "------------------------------------\n",
      "Test Loss: 177.85910624476037\n",
      "Test Loss: 0.0913824322115209\n",
      "Epoch 86\n",
      "------------------------------------\n",
      "Test Loss: 102.49267549297943\n",
      "Test Loss: 1665.0262042594188\n",
      "Epoch 87\n",
      "------------------------------------\n",
      "Test Loss: 493.2940348189598\n",
      "Test Loss: 188.429598596564\n",
      "Epoch 88\n",
      "------------------------------------\n",
      "Test Loss: 132.9723025185291\n",
      "Test Loss: 6.731416595128018\n",
      "Epoch 89\n",
      "------------------------------------\n",
      "Test Loss: 185.31942912786073\n",
      "Test Loss: 18.70491584324799\n",
      "Epoch 90\n",
      "------------------------------------\n",
      "Test Loss: 101.89124023394928\n",
      "Test Loss: 0.3159239630908962\n",
      "Epoch 91\n",
      "------------------------------------\n",
      "Test Loss: 92.30116024186198\n",
      "Test Loss: 19.451885092378884\n",
      "Epoch 92\n",
      "------------------------------------\n",
      "Test Loss: 89.18427886714815\n",
      "Test Loss: 71.60603225341754\n",
      "Epoch 93\n",
      "------------------------------------\n",
      "Test Loss: 90.53137840588738\n",
      "Test Loss: 88.40069402220415\n",
      "Epoch 94\n",
      "------------------------------------\n",
      "Test Loss: 105.07932670333999\n",
      "Test Loss: 174.62364738112635\n",
      "Epoch 95\n",
      "------------------------------------\n",
      "Test Loss: 105.84622404971583\n",
      "Test Loss: 707.3520043863853\n",
      "Epoch 96\n",
      "------------------------------------\n",
      "Test Loss: 84.1587051060535\n",
      "Test Loss: 423.10381292508896\n",
      "Epoch 97\n",
      "------------------------------------\n",
      "Test Loss: 360.0980397917887\n",
      "Test Loss: 295.07823431400135\n",
      "Epoch 98\n",
      "------------------------------------\n",
      "Test Loss: 287.462948216116\n",
      "Test Loss: 0.14459296647727957\n",
      "Epoch 99\n",
      "------------------------------------\n",
      "Test Loss: 113.16092633795124\n",
      "Test Loss: 30.382290404712663\n",
      "Epoch 100\n",
      "------------------------------------\n",
      "Test Loss: 119.93113853698648\n",
      "Test Loss: 0.5931801713989785\n",
      "Epoch 101\n",
      "------------------------------------\n",
      "Test Loss: 96.05340015582195\n",
      "Test Loss: 22.726065823132334\n",
      "Epoch 102\n",
      "------------------------------------\n",
      "Test Loss: 100.66491418894628\n",
      "Test Loss: 2.0910517470086494\n",
      "Epoch 103\n",
      "------------------------------------\n",
      "Test Loss: 86.83531502533526\n",
      "Test Loss: 96.4668811729232\n",
      "Epoch 104\n",
      "------------------------------------\n",
      "Test Loss: 110.4024732870437\n",
      "Test Loss: 6.573856613055336\n",
      "Epoch 105\n",
      "------------------------------------\n",
      "Test Loss: 108.5484446722032\n",
      "Test Loss: 0.045576744897663196\n",
      "Epoch 106\n",
      "------------------------------------\n",
      "Test Loss: 114.30393204231467\n",
      "Test Loss: 0.27311123241089197\n",
      "Epoch 107\n",
      "------------------------------------\n",
      "Test Loss: 96.86099497444883\n",
      "Test Loss: 0.1868697544564213\n",
      "Epoch 108\n",
      "------------------------------------\n",
      "Test Loss: 99.09565536910016\n",
      "Test Loss: 0.5420525536276013\n",
      "Epoch 109\n",
      "------------------------------------\n",
      "Test Loss: 106.8527665437654\n",
      "Test Loss: 4.9601649116356175\n",
      "Epoch 110\n",
      "------------------------------------\n",
      "Test Loss: 107.251032983893\n",
      "Test Loss: 110.09269446046436\n",
      "Epoch 111\n",
      "------------------------------------\n",
      "Test Loss: 122.00006347845029\n",
      "Test Loss: 419.90210218790077\n",
      "Epoch 112\n",
      "------------------------------------\n",
      "Test Loss: 231.04682672808502\n",
      "Test Loss: 602.6021582691102\n",
      "Epoch 113\n",
      "------------------------------------\n",
      "Test Loss: 153.8631740542196\n",
      "Test Loss: 0.0035674014924831827\n",
      "Epoch 114\n",
      "------------------------------------\n",
      "Test Loss: 115.76386843883742\n",
      "Test Loss: 1195.9597607971289\n",
      "Epoch 115\n",
      "------------------------------------\n",
      "Test Loss: 90.22323949087516\n",
      "Test Loss: 25.07178037906682\n",
      "Epoch 116\n",
      "------------------------------------\n",
      "Test Loss: 1191.5561627474399\n",
      "Test Loss: 153.8768461563154\n",
      "Epoch 117\n",
      "------------------------------------\n",
      "Test Loss: 809.3079829237115\n",
      "Test Loss: 2176.1555837200476\n",
      "Epoch 118\n",
      "------------------------------------\n",
      "Test Loss: 169.46154391084116\n",
      "Test Loss: 47.4405148367666\n",
      "Epoch 119\n",
      "------------------------------------\n",
      "Test Loss: 83.11753849062063\n",
      "Test Loss: 147.3465703382178\n",
      "Epoch 120\n",
      "------------------------------------\n",
      "Test Loss: 67.97823432815552\n",
      "Test Loss: 0.030445872663976404\n",
      "Epoch 121\n",
      "------------------------------------\n",
      "Test Loss: 196.77916354941976\n",
      "Test Loss: 0.019578598783794574\n",
      "Epoch 122\n",
      "------------------------------------\n",
      "Test Loss: 65.30335388230459\n",
      "Test Loss: 677.1675942291508\n",
      "Epoch 123\n",
      "------------------------------------\n",
      "Test Loss: 77.89938865856763\n",
      "Test Loss: 10.026187949686781\n",
      "Epoch 124\n",
      "------------------------------------\n",
      "Test Loss: 118.44304356049804\n",
      "Test Loss: 325.37695428771235\n",
      "Epoch 125\n",
      "------------------------------------\n",
      "Test Loss: 92.80186614251602\n",
      "Test Loss: 53.72957986305576\n",
      "Epoch 126\n",
      "------------------------------------\n",
      "Test Loss: 103.725422822817\n",
      "Test Loss: 3.153263497658936\n",
      "Epoch 127\n",
      "------------------------------------\n",
      "Test Loss: 93.35106725055259\n",
      "Test Loss: 1.480639200065791\n",
      "Epoch 128\n",
      "------------------------------------\n",
      "Test Loss: 83.17153413858618\n",
      "Test Loss: 209.73025068166595\n",
      "Epoch 129\n",
      "------------------------------------\n",
      "Test Loss: 98.44852767715237\n",
      "Test Loss: 0.05798300975188206\n",
      "Epoch 130\n",
      "------------------------------------\n",
      "Test Loss: 71.48711303244846\n",
      "Test Loss: 0.3123575822718692\n",
      "Epoch 131\n",
      "------------------------------------\n",
      "Test Loss: 59.381484488563586\n",
      "Test Loss: 372.3039717172593\n",
      "Epoch 132\n",
      "------------------------------------\n",
      "Test Loss: 62.3074178020136\n",
      "Test Loss: 655.4084614355505\n",
      "Epoch 133\n",
      "------------------------------------\n",
      "Test Loss: 62.6360310371579\n",
      "Test Loss: 2.9658358755609733\n",
      "Epoch 134\n",
      "------------------------------------\n",
      "Test Loss: 142.0854874123479\n",
      "Test Loss: 9.011173122488726\n",
      "Epoch 135\n",
      "------------------------------------\n",
      "Test Loss: 123.83106834002277\n",
      "Test Loss: 0.09775392348781473\n",
      "Epoch 136\n",
      "------------------------------------\n",
      "Test Loss: 146.1148300658637\n",
      "Test Loss: 159.81573918687062\n",
      "Epoch 137\n",
      "------------------------------------\n",
      "Test Loss: 105.83488200391895\n",
      "Test Loss: 0.8528841136598119\n",
      "Epoch 138\n",
      "------------------------------------\n",
      "Test Loss: 117.93506556629396\n",
      "Test Loss: 73.9184611181177\n",
      "Epoch 139\n",
      "------------------------------------\n",
      "Test Loss: 73.5998209120801\n",
      "Test Loss: 812.336936065319\n",
      "Epoch 140\n",
      "------------------------------------\n",
      "Test Loss: 226.23190233224472\n",
      "Test Loss: 0.49787950675016274\n",
      "Epoch 141\n",
      "------------------------------------\n",
      "Test Loss: 106.48379574011169\n",
      "Test Loss: 6.743080615632782\n",
      "Epoch 142\n",
      "------------------------------------\n",
      "Test Loss: 98.0348053987751\n",
      "Test Loss: 1421.1930962559456\n",
      "Epoch 143\n",
      "------------------------------------\n",
      "Test Loss: 117.40237886885276\n",
      "Test Loss: 108.68189010420193\n",
      "Epoch 144\n",
      "------------------------------------\n",
      "Test Loss: 117.26684974252625\n",
      "Test Loss: 544.5717015553855\n",
      "Epoch 145\n",
      "------------------------------------\n",
      "Test Loss: 165.3278794132554\n",
      "Test Loss: 0.07878601455400246\n",
      "Epoch 146\n",
      "------------------------------------\n",
      "Test Loss: 72.3847900301966\n",
      "Test Loss: 0.0017214625744367293\n",
      "Epoch 147\n",
      "------------------------------------\n",
      "Test Loss: 71.08184220112638\n",
      "Test Loss: 28.227664986998928\n",
      "Epoch 148\n",
      "------------------------------------\n",
      "Test Loss: 72.81435657861998\n",
      "Test Loss: 20.23690062850715\n",
      "Epoch 149\n",
      "------------------------------------\n",
      "Test Loss: 109.20438380878568\n",
      "Test Loss: 4.422614292791709\n",
      "Epoch 150\n",
      "------------------------------------\n",
      "Test Loss: 77.50660488336803\n",
      "Test Loss: 75.65780080160046\n",
      "Training complete!\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n------------------------------------\")\n",
    "    train_loop(LFW_train, model, LOSS_FUNCTION, optimizer, LOWEST_LOSS)\n",
    "    test_loop(LFW_test, model, LOSS_FUNCTION, optimizer, LOWEST_LOSS)\n",
    "    X_epochs.append(t)\n",
    "print(\"Training complete!\")\n",
    "print(LOWEST_LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_loss['train'])\n",
    "plt.plot(y_loss['train'])\n",
    "plt.plot(y_loss['test'])\n",
    "#plt.plot(X_epochs)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05dbbb7414389032baa654308b5b2368ed4754b5c0531661864b7939633c6eac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
