{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 150\n",
    "LOSS_FUNCTION = nn.MSELoss()\n",
    "LOWEST_LOSS = 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_loss = {}\n",
    "y_loss['train'] = []\n",
    "y_loss['test'] = []\n",
    "\n",
    "X_epochs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_workflow(input_data, target_value):\n",
    "    X = input_data.drop([target_value], axis=1)\n",
    "    y = input_data[target_value]\n",
    "\n",
    "    #print(X)\n",
    "    #print(y)\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    X = torch.from_numpy(X)\n",
    "    y = torch.from_numpy(y)\n",
    "\n",
    "    data = TensorDataset(X, y)\n",
    "\n",
    "    train_ds, test_ds = train_test_split(data, test_size=0.2, random_state=25)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    print(f\"training data: {train_dl}\\n test data: {test_dl}\")\n",
    "    return train_dl, test_dl\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LFW_g</th>\n",
       "      <th>LDW_g</th>\n",
       "      <th>LA_mm2</th>\n",
       "      <th>length_mm</th>\n",
       "      <th>width_mm</th>\n",
       "      <th>height_mm</th>\n",
       "      <th>plant_area</th>\n",
       "      <th>plant_convex_hull_area</th>\n",
       "      <th>plant_solidity</th>\n",
       "      <th>plant_perimeter</th>\n",
       "      <th>plant_width</th>\n",
       "      <th>plant_height</th>\n",
       "      <th>plant_longest_path</th>\n",
       "      <th>plant_convex_hull_vertices</th>\n",
       "      <th>plant_ellipse_major_axis</th>\n",
       "      <th>plant_ellipse_minor_axis</th>\n",
       "      <th>plant_ellipse_angle</th>\n",
       "      <th>plant_ellipse_eccentricity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.30</td>\n",
       "      <td>0.078</td>\n",
       "      <td>31.95</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1211</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>0.831731</td>\n",
       "      <td>189.923880</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>346</td>\n",
       "      <td>16</td>\n",
       "      <td>45.684494</td>\n",
       "      <td>40.965988</td>\n",
       "      <td>92.878510</td>\n",
       "      <td>0.442608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.10</td>\n",
       "      <td>0.148</td>\n",
       "      <td>44.10</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1412</td>\n",
       "      <td>1556.5</td>\n",
       "      <td>0.907164</td>\n",
       "      <td>181.338094</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>370</td>\n",
       "      <td>20</td>\n",
       "      <td>53.368065</td>\n",
       "      <td>37.484673</td>\n",
       "      <td>96.255425</td>\n",
       "      <td>0.711802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.36</td>\n",
       "      <td>0.196</td>\n",
       "      <td>67.61</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1303</td>\n",
       "      <td>1766.5</td>\n",
       "      <td>0.737617</td>\n",
       "      <td>247.865005</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "      <td>333</td>\n",
       "      <td>19</td>\n",
       "      <td>46.356819</td>\n",
       "      <td>43.059174</td>\n",
       "      <td>2.102176</td>\n",
       "      <td>0.370421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.07</td>\n",
       "      <td>0.184</td>\n",
       "      <td>66.98</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1601</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>0.895915</td>\n",
       "      <td>203.480229</td>\n",
       "      <td>44</td>\n",
       "      <td>59</td>\n",
       "      <td>395</td>\n",
       "      <td>21</td>\n",
       "      <td>55.633369</td>\n",
       "      <td>38.548523</td>\n",
       "      <td>15.127802</td>\n",
       "      <td>0.721031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.17</td>\n",
       "      <td>0.187</td>\n",
       "      <td>68.74</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1919</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>0.809022</td>\n",
       "      <td>263.421354</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>454</td>\n",
       "      <td>19</td>\n",
       "      <td>60.012882</td>\n",
       "      <td>48.875011</td>\n",
       "      <td>55.774792</td>\n",
       "      <td>0.580292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>57.96</td>\n",
       "      <td>3.010</td>\n",
       "      <td>726.46</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19084</td>\n",
       "      <td>22974.0</td>\n",
       "      <td>0.830678</td>\n",
       "      <td>767.938160</td>\n",
       "      <td>193</td>\n",
       "      <td>167</td>\n",
       "      <td>1367</td>\n",
       "      <td>33</td>\n",
       "      <td>190.580887</td>\n",
       "      <td>137.733093</td>\n",
       "      <td>62.138748</td>\n",
       "      <td>0.691160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>81.46</td>\n",
       "      <td>3.880</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>18373</td>\n",
       "      <td>21556.5</td>\n",
       "      <td>0.852318</td>\n",
       "      <td>661.612260</td>\n",
       "      <td>164</td>\n",
       "      <td>189</td>\n",
       "      <td>1317</td>\n",
       "      <td>29</td>\n",
       "      <td>176.040924</td>\n",
       "      <td>141.141724</td>\n",
       "      <td>22.056726</td>\n",
       "      <td>0.597653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>140.84</td>\n",
       "      <td>6.380</td>\n",
       "      <td>1707.14</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>23374</td>\n",
       "      <td>26050.0</td>\n",
       "      <td>0.897274</td>\n",
       "      <td>683.754395</td>\n",
       "      <td>186</td>\n",
       "      <td>194</td>\n",
       "      <td>1427</td>\n",
       "      <td>31</td>\n",
       "      <td>191.379974</td>\n",
       "      <td>164.496170</td>\n",
       "      <td>175.959305</td>\n",
       "      <td>0.511091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>108.17</td>\n",
       "      <td>5.250</td>\n",
       "      <td>1364.18</td>\n",
       "      <td>31.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>23457</td>\n",
       "      <td>25678.5</td>\n",
       "      <td>0.913488</td>\n",
       "      <td>671.754395</td>\n",
       "      <td>198</td>\n",
       "      <td>179</td>\n",
       "      <td>1364</td>\n",
       "      <td>31</td>\n",
       "      <td>194.815384</td>\n",
       "      <td>159.870819</td>\n",
       "      <td>122.656914</td>\n",
       "      <td>0.571464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>64.40</td>\n",
       "      <td>3.350</td>\n",
       "      <td>812.24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>18533</td>\n",
       "      <td>22886.5</td>\n",
       "      <td>0.809779</td>\n",
       "      <td>821.595015</td>\n",
       "      <td>189</td>\n",
       "      <td>168</td>\n",
       "      <td>1376</td>\n",
       "      <td>22</td>\n",
       "      <td>193.579941</td>\n",
       "      <td>133.306320</td>\n",
       "      <td>123.732269</td>\n",
       "      <td>0.725106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LFW_g  LDW_g   LA_mm2  length_mm  width_mm  height_mm  plant_area  \\\n",
       "0      1.30  0.078    31.95        4.3       5.2        5.8        1211   \n",
       "1      2.10  0.148    44.10        5.3       5.7        5.5        1412   \n",
       "2      3.36  0.196    67.61        7.3       6.5        8.9        1303   \n",
       "3      3.07  0.184    66.98        5.8       7.6        7.5        1601   \n",
       "4      3.17  0.187    68.74        7.2       8.0        7.1        1919   \n",
       "..      ...    ...      ...        ...       ...        ...         ...   \n",
       "160   57.96  3.010   726.46       18.5      18.5       13.0       19084   \n",
       "161   81.46  3.880  1001.79       21.0      21.5       14.8       18373   \n",
       "162  140.84  6.380  1707.14       23.0      22.5       16.9       23374   \n",
       "163  108.17  5.250  1364.18       31.4      20.5       16.6       23457   \n",
       "164   64.40  3.350   812.24       21.0      18.0       14.7       18533   \n",
       "\n",
       "     plant_convex_hull_area  plant_solidity  plant_perimeter  plant_width  \\\n",
       "0                    1456.0        0.831731       189.923880           49   \n",
       "1                    1556.5        0.907164       181.338094           56   \n",
       "2                    1766.5        0.737617       247.865005           49   \n",
       "3                    1787.0        0.895915       203.480229           44   \n",
       "4                    2372.0        0.809022       263.421354           62   \n",
       "..                      ...             ...              ...          ...   \n",
       "160                 22974.0        0.830678       767.938160          193   \n",
       "161                 21556.5        0.852318       661.612260          164   \n",
       "162                 26050.0        0.897274       683.754395          186   \n",
       "163                 25678.5        0.913488       671.754395          198   \n",
       "164                 22886.5        0.809779       821.595015          189   \n",
       "\n",
       "     plant_height  plant_longest_path  plant_convex_hull_vertices  \\\n",
       "0              42                 346                          16   \n",
       "1              41                 370                          20   \n",
       "2              54                 333                          19   \n",
       "3              59                 395                          21   \n",
       "4              58                 454                          19   \n",
       "..            ...                 ...                         ...   \n",
       "160           167                1367                          33   \n",
       "161           189                1317                          29   \n",
       "162           194                1427                          31   \n",
       "163           179                1364                          31   \n",
       "164           168                1376                          22   \n",
       "\n",
       "     plant_ellipse_major_axis  plant_ellipse_minor_axis  plant_ellipse_angle  \\\n",
       "0                   45.684494                 40.965988            92.878510   \n",
       "1                   53.368065                 37.484673            96.255425   \n",
       "2                   46.356819                 43.059174             2.102176   \n",
       "3                   55.633369                 38.548523            15.127802   \n",
       "4                   60.012882                 48.875011            55.774792   \n",
       "..                        ...                       ...                  ...   \n",
       "160                190.580887                137.733093            62.138748   \n",
       "161                176.040924                141.141724            22.056726   \n",
       "162                191.379974                164.496170           175.959305   \n",
       "163                194.815384                159.870819           122.656914   \n",
       "164                193.579941                133.306320           123.732269   \n",
       "\n",
       "     plant_ellipse_eccentricity  \n",
       "0                      0.442608  \n",
       "1                      0.711802  \n",
       "2                      0.370421  \n",
       "3                      0.721031  \n",
       "4                      0.580292  \n",
       "..                          ...  \n",
       "160                    0.691160  \n",
       "161                    0.597653  \n",
       "162                    0.511091  \n",
       "163                    0.571464  \n",
       "164                    0.725106  \n",
       "\n",
       "[165 rows x 18 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_filepath = \"./final_harvest_data.csv\"\n",
    "\n",
    "data = pd.read_csv(csv_filepath)\n",
    "DATA = data.drop(['date', 'index', 'plant_id', 'tray_id', 'row', 'column'], axis=1)\n",
    "\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: <torch.utils.data.dataloader.DataLoader object at 0x7f92c73d0040>\n",
      " test data: <torch.utils.data.dataloader.DataLoader object at 0x7f92c7121e20>\n"
     ]
    }
   ],
   "source": [
    "LFW_train, LFW_test = data_workflow(DATA, 'LFW_g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(17, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "            \n",
    "        ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits.double()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepNeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=17, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DeepNeuralNetwork()\n",
    "model = model.double()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataset, model, loss_function, optimizer, filler):\n",
    "    model.train()\n",
    "    for (X, y) in dataset:\n",
    "        #X, y = X.to('cuda'), y.to('cuda')\n",
    "        y = y.view(-1,1) \n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model(X)\n",
    "        loss = loss_function(prediction, y)\n",
    "\n",
    "        y_loss['train'].append(loss.item())\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global LOWEST_LOSS\n",
    "        \n",
    "        print(f\"Loss: {loss}\")\n",
    "        if (loss < LOWEST_LOSS):\n",
    "            LOWEST_LOSS = loss\n",
    "        #print(f\"X: {X} \\n Y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataset, model, loss_function, optimizer, filler):\n",
    "    \n",
    "    for (X, y) in dataset:\n",
    "        #X, y = X.to('cuda'), y.to('cuda')\n",
    "        y = y.view(-1,1) \n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model(X)\n",
    "        loss = loss_function(prediction, y)\n",
    "\n",
    "        y_loss['test'].append(loss.item())\n",
    "        y_loss['test'].append(loss.item())\n",
    "        if (randint(0,100) < 50):\n",
    "            y_loss['test'].append(loss.item())\n",
    "\n",
    " \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global LOWEST_LOSS\n",
    "        \n",
    "        print(f\"Test Loss: {loss}\")\n",
    "        \n",
    "        #print(f\"X: {X} \\n Y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------------\n",
      "Loss: 1711.4879924052043\n",
      "Loss: 501747.07980719674\n",
      "Loss: 28954.63832118937\n",
      "Loss: 31116.65455842917\n",
      "Loss: 145799.41497881425\n",
      "Test Loss: 73287.02675679918\n",
      "Test Loss: 797.5103827128048\n",
      "Epoch 2\n",
      "------------------------------------\n",
      "Loss: 11355.929042035592\n",
      "Loss: 2574.9661570387616\n",
      "Loss: 500.58914448699056\n",
      "Loss: 6710.133269233986\n",
      "Loss: 34968.19503746668\n",
      "Test Loss: 198.42323276884338\n",
      "Test Loss: 1.7664515211214404\n",
      "Epoch 3\n",
      "------------------------------------\n",
      "Loss: 6401.598192191775\n",
      "Loss: 10714.484029238389\n",
      "Loss: 9744.452382591795\n",
      "Loss: 7695.320618955872\n",
      "Loss: 3275.539951228861\n",
      "Test Loss: 417.8188844753367\n",
      "Test Loss: 999.9982905335027\n",
      "Epoch 4\n",
      "------------------------------------\n",
      "Loss: 1684.4508921855304\n",
      "Loss: 4208.304166888015\n",
      "Loss: 2132.709536990068\n",
      "Loss: 6784.584193680972\n",
      "Loss: 76.87927675183187\n",
      "Test Loss: 614.0917492988842\n",
      "Test Loss: 0.8069246260713916\n",
      "Epoch 5\n",
      "------------------------------------\n",
      "Loss: 1490.3553034534548\n",
      "Loss: 3275.2201663759365\n",
      "Loss: 3386.962875456083\n",
      "Loss: 1637.8689217176602\n",
      "Loss: 463.8694005032329\n",
      "Test Loss: 216.83511068749237\n",
      "Test Loss: 1.536079706266288\n",
      "Epoch 6\n",
      "------------------------------------\n",
      "Loss: 5176.703781302061\n",
      "Loss: 4205.738727577913\n",
      "Loss: 420.91428824772026\n",
      "Loss: 175.00508194621514\n",
      "Loss: 149.14938539386074\n",
      "Test Loss: 601.3032078371939\n",
      "Test Loss: 785.3964817338554\n",
      "Epoch 7\n",
      "------------------------------------\n",
      "Loss: 1068.9073052873964\n",
      "Loss: 466.15274555447274\n",
      "Loss: 602.6211055280907\n",
      "Loss: 295.61350327602315\n",
      "Loss: 73.69530635228436\n",
      "Test Loss: 196.5748644051006\n",
      "Test Loss: 3.5140256377392216\n",
      "Epoch 8\n",
      "------------------------------------\n",
      "Loss: 251.56334158354497\n",
      "Loss: 2939.147659828135\n",
      "Loss: 269.8113970641512\n",
      "Loss: 273.62810207290516\n",
      "Loss: 400.51177240523293\n",
      "Test Loss: 333.75096552194566\n",
      "Test Loss: 81.2546395985331\n",
      "Epoch 9\n",
      "------------------------------------\n",
      "Loss: 434.0862610778142\n",
      "Loss: 572.8576091273857\n",
      "Loss: 487.6936340302028\n",
      "Loss: 725.0442799275309\n",
      "Loss: 176.8350808648991\n",
      "Test Loss: 252.20598864010654\n",
      "Test Loss: 408.67913436327046\n",
      "Epoch 10\n",
      "------------------------------------\n",
      "Loss: 830.2677475020918\n",
      "Loss: 304.5293033456086\n",
      "Loss: 1146.9517998058216\n",
      "Loss: 210.2099358236257\n",
      "Loss: 816.8860761455055\n",
      "Test Loss: 182.77887236155257\n",
      "Test Loss: 24.314840681026695\n",
      "Epoch 11\n",
      "------------------------------------\n",
      "Loss: 131.31994623858523\n",
      "Loss: 311.35783789411835\n",
      "Loss: 1444.982136560503\n",
      "Loss: 279.71304656647254\n",
      "Loss: 949.7645615675631\n",
      "Test Loss: 332.254209671952\n",
      "Test Loss: 42.01075166407623\n",
      "Epoch 12\n",
      "------------------------------------\n",
      "Loss: 667.5739073898233\n",
      "Loss: 104.13571927894459\n",
      "Loss: 407.67405091866783\n",
      "Loss: 685.0576593447789\n",
      "Loss: 116.7968295676549\n",
      "Test Loss: 194.95529863762252\n",
      "Test Loss: 59.466917900701695\n",
      "Epoch 13\n",
      "------------------------------------\n",
      "Loss: 251.7256664396461\n",
      "Loss: 485.16813113198475\n",
      "Loss: 768.57558173097\n",
      "Loss: 319.35359381150937\n",
      "Loss: 155.9521818888434\n",
      "Test Loss: 272.32255770535613\n",
      "Test Loss: 13.024970922015374\n",
      "Epoch 14\n",
      "------------------------------------\n",
      "Loss: 202.03437756335893\n",
      "Loss: 595.0737983947138\n",
      "Loss: 628.7726722260968\n",
      "Loss: 221.55116348600336\n",
      "Loss: 51.0467621383992\n",
      "Test Loss: 247.70063122639453\n",
      "Test Loss: 4.568028884556177\n",
      "Epoch 15\n",
      "------------------------------------\n",
      "Loss: 175.808305406785\n",
      "Loss: 102.16399436068244\n",
      "Loss: 833.7025867064889\n",
      "Loss: 441.20053795406153\n",
      "Loss: 1180.8685791161965\n",
      "Test Loss: 180.33744984814504\n",
      "Test Loss: 345.25827939884954\n",
      "Epoch 16\n",
      "------------------------------------\n",
      "Loss: 170.74825892168136\n",
      "Loss: 1503.78229636149\n",
      "Loss: 242.27572254392126\n",
      "Loss: 216.70191552735548\n",
      "Loss: 220.0494306959756\n",
      "Test Loss: 206.4754621022011\n",
      "Test Loss: 1143.4072231305508\n",
      "Epoch 17\n",
      "------------------------------------\n",
      "Loss: 111.80294350723716\n",
      "Loss: 276.24325187208393\n",
      "Loss: 1066.7242502622737\n",
      "Loss: 173.22989046877314\n",
      "Loss: 89.2524226155666\n",
      "Test Loss: 158.97599398169706\n",
      "Test Loss: 12.585114348211977\n",
      "Epoch 18\n",
      "------------------------------------\n",
      "Loss: 588.2512059102801\n",
      "Loss: 395.42834740281154\n",
      "Loss: 129.40846200651677\n",
      "Loss: 132.75580707323311\n",
      "Loss: 408.1476146421577\n",
      "Test Loss: 151.58686312082617\n",
      "Test Loss: 0.39260192243136594\n",
      "Epoch 19\n",
      "------------------------------------\n",
      "Loss: 322.47743588530477\n",
      "Loss: 406.2889028964734\n",
      "Loss: 279.3250170841449\n",
      "Loss: 124.08175555882018\n",
      "Loss: 161.52473862778555\n",
      "Test Loss: 111.21568837891985\n",
      "Test Loss: 3.3711954464213703\n",
      "Epoch 20\n",
      "------------------------------------\n",
      "Loss: 658.0535609444478\n",
      "Loss: 184.9802130206108\n",
      "Loss: 438.7692503001846\n",
      "Loss: 222.51165686434143\n",
      "Loss: 422.90415062836996\n",
      "Test Loss: 173.314171554401\n",
      "Test Loss: 199.05057971710775\n",
      "Epoch 21\n",
      "------------------------------------\n",
      "Loss: 288.07941081365664\n",
      "Loss: 861.7870927733195\n",
      "Loss: 364.5394525081226\n",
      "Loss: 337.1768204033868\n",
      "Loss: 114.77817611216193\n",
      "Test Loss: 296.246980509596\n",
      "Test Loss: 838.8576158243261\n",
      "Epoch 22\n",
      "------------------------------------\n",
      "Loss: 360.2385311282416\n",
      "Loss: 366.700311665604\n",
      "Loss: 700.0428450588524\n",
      "Loss: 187.07586805340804\n",
      "Loss: 19.96343072000645\n",
      "Test Loss: 145.9787826305132\n",
      "Test Loss: 0.016343440696748788\n",
      "Epoch 23\n",
      "------------------------------------\n",
      "Loss: 108.7888918868754\n",
      "Loss: 511.38921320438664\n",
      "Loss: 434.25811617817465\n",
      "Loss: 254.433438814527\n",
      "Loss: 936.6269783897252\n",
      "Test Loss: 203.57468009070197\n",
      "Test Loss: 2.3242523885123316\n",
      "Epoch 24\n",
      "------------------------------------\n",
      "Loss: 357.55002444854046\n",
      "Loss: 1272.7080837416697\n",
      "Loss: 229.5416711139224\n",
      "Loss: 292.90178498018736\n",
      "Loss: 25.62041724051129\n",
      "Test Loss: 366.696313522161\n",
      "Test Loss: 1643.6207281424815\n",
      "Epoch 25\n",
      "------------------------------------\n",
      "Loss: 718.8887067968943\n",
      "Loss: 233.57860760463979\n",
      "Loss: 408.8094768886782\n",
      "Loss: 1051.5003143959111\n",
      "Loss: 4.171635883027919\n",
      "Test Loss: 1493.0790171381311\n",
      "Test Loss: 2.68125001142375\n",
      "Epoch 26\n",
      "------------------------------------\n",
      "Loss: 1137.3793563906258\n",
      "Loss: 242.68923615012727\n",
      "Loss: 294.58561231418196\n",
      "Loss: 338.8460300577187\n",
      "Loss: 215.74402613638895\n",
      "Test Loss: 307.4739772250279\n",
      "Test Loss: 2997.7536754233\n",
      "Epoch 27\n",
      "------------------------------------\n",
      "Loss: 355.43942200841263\n",
      "Loss: 805.0486706409238\n",
      "Loss: 972.1630773725112\n",
      "Loss: 2663.3402813344414\n",
      "Loss: 543.4708888654607\n",
      "Test Loss: 1583.9554066457918\n",
      "Test Loss: 138.3864985063679\n",
      "Epoch 28\n",
      "------------------------------------\n",
      "Loss: 341.619933558021\n",
      "Loss: 187.77182796219023\n",
      "Loss: 752.7454234710203\n",
      "Loss: 1173.4529108885492\n",
      "Loss: 214.9355379513254\n",
      "Test Loss: 156.18572203135827\n",
      "Test Loss: 49.88721765057006\n",
      "Epoch 29\n",
      "------------------------------------\n",
      "Loss: 240.04678359390394\n",
      "Loss: 199.34575454207612\n",
      "Loss: 443.9559165630207\n",
      "Loss: 448.3481497345224\n",
      "Loss: 156.09164435651286\n",
      "Test Loss: 192.4808393713169\n",
      "Test Loss: 4.647324171969521\n",
      "Epoch 30\n",
      "------------------------------------\n",
      "Loss: 228.64181844328724\n",
      "Loss: 218.6896716896744\n",
      "Loss: 318.0726040938562\n",
      "Loss: 340.84651532353877\n",
      "Loss: 376.9810449218959\n",
      "Test Loss: 148.66436949287763\n",
      "Test Loss: 310.9116391408858\n",
      "Epoch 31\n",
      "------------------------------------\n",
      "Loss: 195.1239533434204\n",
      "Loss: 308.0993443596559\n",
      "Loss: 250.46515333478203\n",
      "Loss: 143.036388939833\n",
      "Loss: 24.98208142405299\n",
      "Test Loss: 96.46586395740343\n",
      "Test Loss: 45.12645607040788\n",
      "Epoch 32\n",
      "------------------------------------\n",
      "Loss: 373.91230895432136\n",
      "Loss: 182.65128798817824\n",
      "Loss: 154.38544328926918\n",
      "Loss: 348.2811756113206\n",
      "Loss: 1215.2210103213122\n",
      "Test Loss: 121.57312982321186\n",
      "Test Loss: 33.438174679160724\n",
      "Epoch 33\n",
      "------------------------------------\n",
      "Loss: 358.27685360747955\n",
      "Loss: 178.22229630758676\n",
      "Loss: 214.06674840388058\n",
      "Loss: 392.76089088929655\n",
      "Loss: 50.86012832288896\n",
      "Test Loss: 102.56791995655726\n",
      "Test Loss: 1.587105672711442\n",
      "Epoch 34\n",
      "------------------------------------\n",
      "Loss: 281.09832599611536\n",
      "Loss: 238.87903572901388\n",
      "Loss: 282.0305220286195\n",
      "Loss: 143.44848647631002\n",
      "Loss: 163.3993782384553\n",
      "Test Loss: 85.28801462810542\n",
      "Test Loss: 22.480264862709195\n",
      "Epoch 35\n",
      "------------------------------------\n",
      "Loss: 382.99647548877033\n",
      "Loss: 142.45540812072508\n",
      "Loss: 73.74836314065868\n",
      "Loss: 182.73556061556246\n",
      "Loss: 497.8660471428176\n",
      "Test Loss: 75.9714972496528\n",
      "Test Loss: 956.1925672532137\n",
      "Epoch 36\n",
      "------------------------------------\n",
      "Loss: 228.0460582387243\n",
      "Loss: 243.99591354292824\n",
      "Loss: 756.9122502210046\n",
      "Loss: 480.98576194623604\n",
      "Loss: 191.53066022921897\n",
      "Test Loss: 122.342955976045\n",
      "Test Loss: 7.72541840138248\n",
      "Epoch 37\n",
      "------------------------------------\n",
      "Loss: 463.35517197232366\n",
      "Loss: 710.591500601022\n",
      "Loss: 650.4730351431934\n",
      "Loss: 92.15200958067649\n",
      "Loss: 99.67301054454005\n",
      "Test Loss: 226.28728407751413\n",
      "Test Loss: 66.56675907878726\n",
      "Epoch 38\n",
      "------------------------------------\n",
      "Loss: 390.0341363656411\n",
      "Loss: 1071.6459773184638\n",
      "Loss: 384.9543428986722\n",
      "Loss: 180.81980226665422\n",
      "Loss: 1339.4797025070875\n",
      "Test Loss: 317.7064350358422\n",
      "Test Loss: 2.494480574811091\n",
      "Epoch 39\n",
      "------------------------------------\n",
      "Loss: 488.6677171272452\n",
      "Loss: 99.6875060527473\n",
      "Loss: 188.76950634626957\n",
      "Loss: 195.76724930118942\n",
      "Loss: 513.3065648246678\n",
      "Test Loss: 108.6069426838531\n",
      "Test Loss: 131.71350244662176\n",
      "Epoch 40\n",
      "------------------------------------\n",
      "Loss: 119.84096358593985\n",
      "Loss: 284.90622911073507\n",
      "Loss: 339.06350969419\n",
      "Loss: 125.12693340562686\n",
      "Loss: 141.5106614209639\n",
      "Test Loss: 200.3482285479662\n",
      "Test Loss: 0.764723563226852\n",
      "Epoch 41\n",
      "------------------------------------\n",
      "Loss: 183.7160835559842\n",
      "Loss: 245.65562272782265\n",
      "Loss: 228.50606205160796\n",
      "Loss: 223.51080968116483\n",
      "Loss: 149.12585669190784\n",
      "Test Loss: 102.55222812196361\n",
      "Test Loss: 86.16210551550586\n",
      "Epoch 42\n",
      "------------------------------------\n",
      "Loss: 180.22503970876193\n",
      "Loss: 81.44125827859932\n",
      "Loss: 218.78170188835853\n",
      "Loss: 246.83593283936546\n",
      "Loss: 101.61118264661076\n",
      "Test Loss: 88.62221714597928\n",
      "Test Loss: 370.4011167436185\n",
      "Epoch 43\n",
      "------------------------------------\n",
      "Loss: 294.58488418333974\n",
      "Loss: 156.82852107057045\n",
      "Loss: 222.72977994304182\n",
      "Loss: 201.95341561504378\n",
      "Loss: 12.77614627238256\n",
      "Test Loss: 97.63825122102429\n",
      "Test Loss: 57.64209785779219\n",
      "Epoch 44\n",
      "------------------------------------\n",
      "Loss: 79.49023188564269\n",
      "Loss: 182.50692432473681\n",
      "Loss: 179.47637125578908\n",
      "Loss: 231.75502774890913\n",
      "Loss: 15.641851590652735\n",
      "Test Loss: 90.4519037512674\n",
      "Test Loss: 0.3685990602415252\n",
      "Epoch 45\n",
      "------------------------------------\n",
      "Loss: 215.7396633453642\n",
      "Loss: 217.39863250739864\n",
      "Loss: 109.28499982549852\n",
      "Loss: 70.78151027631588\n",
      "Loss: 99.56894480055273\n",
      "Test Loss: 130.2532610166173\n",
      "Test Loss: 1.2805633500199693\n",
      "Epoch 46\n",
      "------------------------------------\n",
      "Loss: 160.17439439013478\n",
      "Loss: 168.13784680557683\n",
      "Loss: 79.60916537038787\n",
      "Loss: 240.381036667805\n",
      "Loss: 54.77363496023515\n",
      "Test Loss: 93.98636235511995\n",
      "Test Loss: 1.8004697721368301\n",
      "Epoch 47\n",
      "------------------------------------\n",
      "Loss: 135.52251544832643\n",
      "Loss: 162.2965293846279\n",
      "Loss: 206.87727016805974\n",
      "Loss: 73.00800218055497\n",
      "Loss: 40.49807327499215\n",
      "Test Loss: 112.50700698675891\n",
      "Test Loss: 175.2492328605544\n",
      "Epoch 48\n",
      "------------------------------------\n",
      "Loss: 304.4849623950208\n",
      "Loss: 411.9649148015212\n",
      "Loss: 294.6060793923252\n",
      "Loss: 165.20659629720296\n",
      "Loss: 393.4609964010852\n",
      "Test Loss: 137.91972679472934\n",
      "Test Loss: 0.26882036573678003\n",
      "Epoch 49\n",
      "------------------------------------\n",
      "Loss: 382.85031055712693\n",
      "Loss: 151.8501035595644\n",
      "Loss: 258.51234227102987\n",
      "Loss: 80.31183959190402\n",
      "Loss: 923.1808641483899\n",
      "Test Loss: 93.32995542858879\n",
      "Test Loss: 5.333954159508297\n",
      "Epoch 50\n",
      "------------------------------------\n",
      "Loss: 548.1272567238427\n",
      "Loss: 557.569134993875\n",
      "Loss: 181.55488280490806\n",
      "Loss: 348.80440622253354\n",
      "Loss: 79.19909803414073\n",
      "Test Loss: 388.65565065354076\n",
      "Test Loss: 5.877096363051967\n",
      "Epoch 51\n",
      "------------------------------------\n",
      "Loss: 927.6855614048991\n",
      "Loss: 813.9080956130986\n",
      "Loss: 365.4169582303728\n",
      "Loss: 69.70481063474281\n",
      "Loss: 33.54402902661403\n",
      "Test Loss: 351.85833106142974\n",
      "Test Loss: 4.766830943781378\n",
      "Epoch 52\n",
      "------------------------------------\n",
      "Loss: 1108.9585419741877\n",
      "Loss: 456.5271538262509\n",
      "Loss: 488.49325679768657\n",
      "Loss: 77.07592639545565\n",
      "Loss: 1246.6821791928473\n",
      "Test Loss: 330.9378774803739\n",
      "Test Loss: 0.13060697163629698\n",
      "Epoch 53\n",
      "------------------------------------\n",
      "Loss: 485.3000483419361\n",
      "Loss: 105.27104182036064\n",
      "Loss: 288.7388567964265\n",
      "Loss: 122.2690229099179\n",
      "Loss: 20.80645374781902\n",
      "Test Loss: 139.3463072304522\n",
      "Test Loss: 0.219569766817443\n",
      "Epoch 54\n",
      "------------------------------------\n",
      "Loss: 271.1398138144028\n",
      "Loss: 452.54372551032975\n",
      "Loss: 154.9548054042681\n",
      "Loss: 219.35554322311765\n",
      "Loss: 222.26207629624446\n",
      "Test Loss: 155.4779867397305\n",
      "Test Loss: 28.20316199787308\n",
      "Epoch 55\n",
      "------------------------------------\n",
      "Loss: 302.50587366813664\n",
      "Loss: 69.78120018578413\n",
      "Loss: 188.67932251649833\n",
      "Loss: 169.0226601177917\n",
      "Loss: 730.1840445338307\n",
      "Test Loss: 106.05962925385514\n",
      "Test Loss: 353.5797940922125\n",
      "Epoch 56\n",
      "------------------------------------\n",
      "Loss: 161.0288073764653\n",
      "Loss: 93.30206324457843\n",
      "Loss: 160.34023768083682\n",
      "Loss: 263.3447555540752\n",
      "Loss: 1.2050213585328178\n",
      "Test Loss: 110.5720929097992\n",
      "Test Loss: 84.22750555860476\n",
      "Epoch 57\n",
      "------------------------------------\n",
      "Loss: 320.41273469163343\n",
      "Loss: 261.64242844350986\n",
      "Loss: 347.46068223268014\n",
      "Loss: 271.18406355005106\n",
      "Loss: 74.34500210957779\n",
      "Test Loss: 138.51371328556135\n",
      "Test Loss: 0.9539649463887229\n",
      "Epoch 58\n",
      "------------------------------------\n",
      "Loss: 370.2698007373393\n",
      "Loss: 243.2833639542544\n",
      "Loss: 430.7379411296844\n",
      "Loss: 169.11038519311705\n",
      "Loss: 26.94497464268757\n",
      "Test Loss: 208.2088319241954\n",
      "Test Loss: 1.8742065610371488\n",
      "Epoch 59\n",
      "------------------------------------\n",
      "Loss: 379.5248662530563\n",
      "Loss: 176.7508404148004\n",
      "Loss: 451.9936910373801\n",
      "Loss: 123.98759172802737\n",
      "Loss: 122.70754028752714\n",
      "Test Loss: 141.69441964490673\n",
      "Test Loss: 8.27975937990345\n",
      "Epoch 60\n",
      "------------------------------------\n",
      "Loss: 176.96933012041984\n",
      "Loss: 255.60178652379506\n",
      "Loss: 253.3291661637782\n",
      "Loss: 165.8503506954678\n",
      "Loss: 315.45658567682483\n",
      "Test Loss: 156.8687970565045\n",
      "Test Loss: 400.8572283533608\n",
      "Epoch 61\n",
      "------------------------------------\n",
      "Loss: 225.90637894636603\n",
      "Loss: 164.79485100527592\n",
      "Loss: 394.56074705418473\n",
      "Loss: 240.58851493366595\n",
      "Loss: 125.31408134525435\n",
      "Test Loss: 157.72983060244772\n",
      "Test Loss: 97.91580465478445\n",
      "Epoch 62\n",
      "------------------------------------\n",
      "Loss: 251.18968455144974\n",
      "Loss: 229.32982035450982\n",
      "Loss: 193.15107200908295\n",
      "Loss: 148.68337231089635\n",
      "Loss: 72.25475949278268\n",
      "Test Loss: 159.30668595233496\n",
      "Test Loss: 0.0801208696475088\n",
      "Epoch 63\n",
      "------------------------------------\n",
      "Loss: 251.86837521763516\n",
      "Loss: 143.73355012236811\n",
      "Loss: 179.19511498487486\n",
      "Loss: 169.5802426743114\n",
      "Loss: 223.5014895128823\n",
      "Test Loss: 129.19514974715523\n",
      "Test Loss: 411.49625494805696\n",
      "Epoch 64\n",
      "------------------------------------\n",
      "Loss: 202.37746616340118\n",
      "Loss: 137.41819998474574\n",
      "Loss: 374.10316306777577\n",
      "Loss: 195.24968927871964\n",
      "Loss: 38.55520757962219\n",
      "Test Loss: 109.72564627005147\n",
      "Test Loss: 8.720778856648971\n",
      "Epoch 65\n",
      "------------------------------------\n",
      "Loss: 292.33057474521365\n",
      "Loss: 251.69420281721344\n",
      "Loss: 154.71739024454862\n",
      "Loss: 170.28824584534595\n",
      "Loss: 275.9590757752267\n",
      "Test Loss: 135.37801210631437\n",
      "Test Loss: 0.17510030829471873\n",
      "Epoch 66\n",
      "------------------------------------\n",
      "Loss: 165.40919623747783\n",
      "Loss: 208.55625686353687\n",
      "Loss: 284.7537858482041\n",
      "Loss: 147.13499004704397\n",
      "Loss: 26.60446836804433\n",
      "Test Loss: 128.33304045010655\n",
      "Test Loss: 7.1697520681295765\n",
      "Epoch 67\n",
      "------------------------------------\n",
      "Loss: 538.3184171509042\n",
      "Loss: 311.8877548873106\n",
      "Loss: 205.929309670637\n",
      "Loss: 93.00315019598835\n",
      "Loss: 119.95208003691697\n",
      "Test Loss: 192.27493825121138\n",
      "Test Loss: 25.911481274115513\n",
      "Epoch 68\n",
      "------------------------------------\n",
      "Loss: 163.43495132019336\n",
      "Loss: 253.31794820184518\n",
      "Loss: 195.0709847718763\n",
      "Loss: 223.86670750170373\n",
      "Loss: 373.8735090520445\n",
      "Test Loss: 101.3345382590422\n",
      "Test Loss: 7.019038683809669\n",
      "Epoch 69\n",
      "------------------------------------\n",
      "Loss: 261.0350514956107\n",
      "Loss: 68.62411898059632\n",
      "Loss: 139.03828742597497\n",
      "Loss: 84.92056344269616\n",
      "Loss: 15.916620558861595\n",
      "Test Loss: 96.7598974350397\n",
      "Test Loss: 125.29394983342819\n",
      "Epoch 70\n",
      "------------------------------------\n",
      "Loss: 96.88428636397308\n",
      "Loss: 308.1011542668017\n",
      "Loss: 195.46133455186185\n",
      "Loss: 170.71923959586456\n",
      "Loss: 139.10649457193827\n",
      "Test Loss: 116.87007112831107\n",
      "Test Loss: 1.217740597899438\n",
      "Epoch 71\n",
      "------------------------------------\n",
      "Loss: 258.1357655693899\n",
      "Loss: 316.5144159295649\n",
      "Loss: 177.68871538213517\n",
      "Loss: 102.57014746448172\n",
      "Loss: 333.65262996170105\n",
      "Test Loss: 154.43669697686326\n",
      "Test Loss: 939.6696412799668\n",
      "Epoch 72\n",
      "------------------------------------\n",
      "Loss: 150.8395816454223\n",
      "Loss: 133.78956884614442\n",
      "Loss: 99.41660440768507\n",
      "Loss: 172.71544376051804\n",
      "Loss: 64.31288424014323\n",
      "Test Loss: 223.51365565350187\n",
      "Test Loss: 20.02392690792008\n",
      "Epoch 73\n",
      "------------------------------------\n",
      "Loss: 120.49857875636454\n",
      "Loss: 182.89819363549057\n",
      "Loss: 64.03918287309979\n",
      "Loss: 203.88411168014144\n",
      "Loss: 144.5253750524036\n",
      "Test Loss: 88.71623584067912\n",
      "Test Loss: 9.892990203631184\n",
      "Epoch 74\n",
      "------------------------------------\n",
      "Loss: 101.11329020772033\n",
      "Loss: 87.66821221922307\n",
      "Loss: 90.652778143321\n",
      "Loss: 204.2142796787903\n",
      "Loss: 513.312277791179\n",
      "Test Loss: 102.09856991719494\n",
      "Test Loss: 0.015339915617640601\n",
      "Epoch 75\n",
      "------------------------------------\n",
      "Loss: 213.4595957386359\n",
      "Loss: 284.69852308354353\n",
      "Loss: 417.12961785703703\n",
      "Loss: 227.76388462840976\n",
      "Loss: 8.345182809472377\n",
      "Test Loss: 327.3531503091574\n",
      "Test Loss: 440.11999840099077\n",
      "Epoch 76\n",
      "------------------------------------\n",
      "Loss: 437.4622251014127\n",
      "Loss: 174.19152646519825\n",
      "Loss: 75.57784009627773\n",
      "Loss: 206.3935699720324\n",
      "Loss: 147.4403828081774\n",
      "Test Loss: 162.52543103001975\n",
      "Test Loss: 1892.8639624563468\n",
      "Epoch 77\n",
      "------------------------------------\n",
      "Loss: 110.51270283895998\n",
      "Loss: 896.8047512439342\n",
      "Loss: 1697.847391068105\n",
      "Loss: 517.3686935426564\n",
      "Loss: 1301.0253645253526\n",
      "Test Loss: 354.5647817289133\n",
      "Test Loss: 287.30294707012837\n",
      "Epoch 78\n",
      "------------------------------------\n",
      "Loss: 104.76688981057207\n",
      "Loss: 769.4738867525712\n",
      "Loss: 200.84584868946422\n",
      "Loss: 182.60700026671176\n",
      "Loss: 1.2553201355578734\n",
      "Test Loss: 123.08444548461274\n",
      "Test Loss: 1.4141863150602068\n",
      "Epoch 79\n",
      "------------------------------------\n",
      "Loss: 293.31927531853614\n",
      "Loss: 98.92141722168527\n",
      "Loss: 126.20484070563981\n",
      "Loss: 299.4004636381008\n",
      "Loss: 102.90137395329499\n",
      "Test Loss: 99.76792781602659\n",
      "Test Loss: 509.1393059429359\n",
      "Epoch 80\n",
      "------------------------------------\n",
      "Loss: 240.12059061304547\n",
      "Loss: 459.8906675450896\n",
      "Loss: 198.62546857124718\n",
      "Loss: 282.7998426534158\n",
      "Loss: 90.7176874088697\n",
      "Test Loss: 75.9171450062961\n",
      "Test Loss: 192.35936914416243\n",
      "Epoch 81\n",
      "------------------------------------\n",
      "Loss: 140.62424875926584\n",
      "Loss: 168.72264205840787\n",
      "Loss: 106.70922099880018\n",
      "Loss: 194.7779866175281\n",
      "Loss: 119.36420973588935\n",
      "Test Loss: 71.13192510351928\n",
      "Test Loss: 18.16429378958381\n",
      "Epoch 82\n",
      "------------------------------------\n",
      "Loss: 155.53972047541632\n",
      "Loss: 154.43195306492566\n",
      "Loss: 204.96465205630545\n",
      "Loss: 102.46805371893613\n",
      "Loss: 58.49434837247612\n",
      "Test Loss: 88.80517655350188\n",
      "Test Loss: 15.016663831792576\n",
      "Epoch 83\n",
      "------------------------------------\n",
      "Loss: 100.93467099985995\n",
      "Loss: 131.9928410973144\n",
      "Loss: 155.66381814809654\n",
      "Loss: 242.96412830942765\n",
      "Loss: 200.32623154872917\n",
      "Test Loss: 61.71073789936247\n",
      "Test Loss: 318.4660823670613\n",
      "Epoch 84\n",
      "------------------------------------\n",
      "Loss: 265.30891238703924\n",
      "Loss: 112.00676098251661\n",
      "Loss: 247.8162141117853\n",
      "Loss: 167.61735098684102\n",
      "Loss: 4.700280184934947\n",
      "Test Loss: 81.99325466252536\n",
      "Test Loss: 10.393698410787321\n",
      "Epoch 85\n",
      "------------------------------------\n",
      "Loss: 127.9876380446177\n",
      "Loss: 364.93177685287606\n",
      "Loss: 149.85786064589973\n",
      "Loss: 58.07353418169738\n",
      "Loss: 56.12416744639347\n",
      "Test Loss: 83.21498350546787\n",
      "Test Loss: 0.9569041410883271\n",
      "Epoch 86\n",
      "------------------------------------\n",
      "Loss: 132.33640976675068\n",
      "Loss: 218.33319414261996\n",
      "Loss: 240.95764081880492\n",
      "Loss: 114.3194512696198\n",
      "Loss: 173.13368107852693\n",
      "Test Loss: 91.37350583220658\n",
      "Test Loss: 157.94435774611972\n",
      "Epoch 87\n",
      "------------------------------------\n",
      "Loss: 211.23947700703394\n",
      "Loss: 131.72589406227\n",
      "Loss: 105.53843326581796\n",
      "Loss: 191.27334623288505\n",
      "Loss: 323.36396450609794\n",
      "Test Loss: 90.70506616056107\n",
      "Test Loss: 0.0523816939003093\n",
      "Epoch 88\n",
      "------------------------------------\n",
      "Loss: 124.84721844820339\n",
      "Loss: 159.1482857692135\n",
      "Loss: 71.1644608711697\n",
      "Loss: 153.0683520674261\n",
      "Loss: 169.80794682387003\n",
      "Test Loss: 130.5543149922835\n",
      "Test Loss: 21.156795671595063\n",
      "Epoch 89\n",
      "------------------------------------\n",
      "Loss: 290.29291351578553\n",
      "Loss: 82.48839856072274\n",
      "Loss: 145.041810281003\n",
      "Loss: 86.50841888126688\n",
      "Loss: 48.46570520703136\n",
      "Test Loss: 78.37567836714169\n",
      "Test Loss: 295.62126857429405\n",
      "Epoch 90\n",
      "------------------------------------\n",
      "Loss: 106.12559986771562\n",
      "Loss: 105.36785096886821\n",
      "Loss: 184.81712863854867\n",
      "Loss: 329.40751898318297\n",
      "Loss: 82.55392586728837\n",
      "Test Loss: 78.58448113175746\n",
      "Test Loss: 9.422525511200757\n",
      "Epoch 91\n",
      "------------------------------------\n",
      "Loss: 271.9166682300315\n",
      "Loss: 158.6605046124413\n",
      "Loss: 176.83185640760732\n",
      "Loss: 129.42345360596786\n",
      "Loss: 8.18248880149687\n",
      "Test Loss: 142.3293817012824\n",
      "Test Loss: 26.583343180718117\n",
      "Epoch 92\n",
      "------------------------------------\n",
      "Loss: 86.39673532944146\n",
      "Loss: 145.91546220955473\n",
      "Loss: 142.92301445453305\n",
      "Loss: 140.2990749859668\n",
      "Loss: 453.57009179632234\n",
      "Test Loss: 82.64420327926786\n",
      "Test Loss: 457.75247765851867\n",
      "Epoch 93\n",
      "------------------------------------\n",
      "Loss: 131.1448043202728\n",
      "Loss: 170.91210709898598\n",
      "Loss: 44.15716085585703\n",
      "Loss: 249.2649752666683\n",
      "Loss: 331.8297095966035\n",
      "Test Loss: 77.74221115663681\n",
      "Test Loss: 0.758797150475621\n",
      "Epoch 94\n",
      "------------------------------------\n",
      "Loss: 180.5445762485487\n",
      "Loss: 151.77163392967114\n",
      "Loss: 364.5446843499205\n",
      "Loss: 60.39374428956841\n",
      "Loss: 54.58376437223849\n",
      "Test Loss: 146.00483696559155\n",
      "Test Loss: 0.02285738604877734\n",
      "Epoch 95\n",
      "------------------------------------\n",
      "Loss: 445.94545644003665\n",
      "Loss: 309.5351310867815\n",
      "Loss: 158.21878042309314\n",
      "Loss: 58.01676593246634\n",
      "Loss: 142.63417457487188\n",
      "Test Loss: 293.38901838878235\n",
      "Test Loss: 33.70927284856561\n",
      "Epoch 96\n",
      "------------------------------------\n",
      "Loss: 284.48120900812273\n",
      "Loss: 204.98616258082518\n",
      "Loss: 68.36499734095695\n",
      "Loss: 103.39855496961079\n",
      "Loss: 97.29713286273139\n",
      "Test Loss: 168.47507429622812\n",
      "Test Loss: 6.504435339374894e-06\n",
      "Epoch 97\n",
      "------------------------------------\n",
      "Loss: 286.9761347652342\n",
      "Loss: 84.98399155734194\n",
      "Loss: 61.172278355976076\n",
      "Loss: 278.1737285844993\n",
      "Loss: 265.1505223511766\n",
      "Test Loss: 149.69035030162283\n",
      "Test Loss: 0.0777667601482051\n",
      "Epoch 98\n",
      "------------------------------------\n",
      "Loss: 116.46034859259949\n",
      "Loss: 114.97679261263086\n",
      "Loss: 98.12037225402814\n",
      "Loss: 129.89345552360737\n",
      "Loss: 268.4899070325085\n",
      "Test Loss: 106.05671136164167\n",
      "Test Loss: 78.88043754117838\n",
      "Epoch 99\n",
      "------------------------------------\n",
      "Loss: 163.1472150897116\n",
      "Loss: 105.97459435254585\n",
      "Loss: 183.29845921872882\n",
      "Loss: 125.91576858418203\n",
      "Loss: 0.49340469087445865\n",
      "Test Loss: 87.46301632880508\n",
      "Test Loss: 0.2401130932189925\n",
      "Epoch 100\n",
      "------------------------------------\n",
      "Loss: 123.68655946117774\n",
      "Loss: 158.00809131187404\n",
      "Loss: 62.95297829134619\n",
      "Loss: 100.95320198525505\n",
      "Loss: 9.599001421915927\n",
      "Test Loss: 54.44050039963511\n",
      "Test Loss: 269.8186915757642\n",
      "Epoch 101\n",
      "------------------------------------\n",
      "Loss: 76.66384308908042\n",
      "Loss: 190.5996360211766\n",
      "Loss: 222.2061539804992\n",
      "Loss: 123.44498366368637\n",
      "Loss: 1.3130329720588865\n",
      "Test Loss: 62.04702384142448\n",
      "Test Loss: 402.19027810062227\n",
      "Epoch 102\n",
      "------------------------------------\n",
      "Loss: 43.338348150941606\n",
      "Loss: 164.53022775563738\n",
      "Loss: 197.23958783800063\n",
      "Loss: 231.2419778067999\n",
      "Loss: 217.51704965738344\n",
      "Test Loss: 77.37228577584824\n",
      "Test Loss: 0.47627439493589235\n",
      "Epoch 103\n",
      "------------------------------------\n",
      "Loss: 183.07839569683176\n",
      "Loss: 400.0337275064336\n",
      "Loss: 159.09940842143425\n",
      "Loss: 93.60344086962591\n",
      "Loss: 3.380387866988487\n",
      "Test Loss: 264.4714305621218\n",
      "Test Loss: 0.1461275979383353\n",
      "Epoch 104\n",
      "------------------------------------\n",
      "Loss: 300.8593048079928\n",
      "Loss: 147.3508853306345\n",
      "Loss: 110.69323016866034\n",
      "Loss: 103.87694509185717\n",
      "Loss: 736.6392450828268\n",
      "Test Loss: 133.45732409683635\n",
      "Test Loss: 0.08926946559426935\n",
      "Epoch 105\n",
      "------------------------------------\n",
      "Loss: 88.96699418689794\n",
      "Loss: 173.30040971661253\n",
      "Loss: 237.82018614002672\n",
      "Loss: 80.36695807449468\n",
      "Loss: 137.39583756885833\n",
      "Test Loss: 70.51019368846914\n",
      "Test Loss: 9.27768190669869\n",
      "Epoch 106\n",
      "------------------------------------\n",
      "Loss: 217.58333266438805\n",
      "Loss: 107.33794549229701\n",
      "Loss: 85.06118041304093\n",
      "Loss: 84.42781500932969\n",
      "Loss: 0.4062681349246535\n",
      "Test Loss: 86.36034086673138\n",
      "Test Loss: 24.229789503062058\n",
      "Epoch 107\n",
      "------------------------------------\n",
      "Loss: 164.8979877371097\n",
      "Loss: 64.28778950429624\n",
      "Loss: 54.99231289874375\n",
      "Loss: 133.47924700463224\n",
      "Loss: 107.31732063923309\n",
      "Test Loss: 67.38370239278606\n",
      "Test Loss: 46.26889657574278\n",
      "Epoch 108\n",
      "------------------------------------\n",
      "Loss: 81.44026170908084\n",
      "Loss: 100.56900927071953\n",
      "Loss: 137.50260427425815\n",
      "Loss: 61.64062624669515\n",
      "Loss: 29.781442709210324\n",
      "Test Loss: 85.01740946941578\n",
      "Test Loss: 0.950097392818334\n",
      "Epoch 109\n",
      "------------------------------------\n",
      "Loss: 133.38089567416114\n",
      "Loss: 97.36608588862913\n",
      "Loss: 41.28331130510714\n",
      "Loss: 103.88536156714756\n",
      "Loss: 54.98425641310298\n",
      "Test Loss: 72.0150092074409\n",
      "Test Loss: 63.218937822919855\n",
      "Epoch 110\n",
      "------------------------------------\n",
      "Loss: 151.6983530869636\n",
      "Loss: 126.02468361640773\n",
      "Loss: 43.24290457817025\n",
      "Loss: 115.62605146384182\n",
      "Loss: 25.702080857889545\n",
      "Test Loss: 109.83758560381547\n",
      "Test Loss: 0.8449392907976182\n",
      "Epoch 111\n",
      "------------------------------------\n",
      "Loss: 172.4518826756222\n",
      "Loss: 90.4271620230044\n",
      "Loss: 112.57263986947558\n",
      "Loss: 90.60836350297282\n",
      "Loss: 78.97737655808804\n",
      "Test Loss: 68.44375400718957\n",
      "Test Loss: 9.17627231275414\n",
      "Epoch 112\n",
      "------------------------------------\n",
      "Loss: 139.98148601256264\n",
      "Loss: 154.1561268548945\n",
      "Loss: 117.83887222420775\n",
      "Loss: 59.13228742674777\n",
      "Loss: 320.27050394426703\n",
      "Test Loss: 54.40590869569938\n",
      "Test Loss: 0.15101141290809278\n",
      "Epoch 113\n",
      "------------------------------------\n",
      "Loss: 156.74347344872285\n",
      "Loss: 117.24295334207066\n",
      "Loss: 114.56529956480068\n",
      "Loss: 86.87931496351389\n",
      "Loss: 0.3250426988327381\n",
      "Test Loss: 61.26759800416906\n",
      "Test Loss: 927.5251992495106\n",
      "Epoch 114\n",
      "------------------------------------\n",
      "Loss: 301.95165459718663\n",
      "Loss: 739.7835763798369\n",
      "Loss: 1410.1700502404874\n",
      "Loss: 192.5745578196204\n",
      "Loss: 178.8931001858324\n",
      "Test Loss: 100.63564382736092\n",
      "Test Loss: 3153.785336063402\n",
      "Epoch 115\n",
      "------------------------------------\n",
      "Loss: 46.372795164941216\n",
      "Loss: 699.5215513003825\n",
      "Loss: 1126.246680527411\n",
      "Loss: 999.8673767794787\n",
      "Loss: 352.97474824785445\n",
      "Test Loss: 516.115969489984\n",
      "Test Loss: 5.906720875644782\n",
      "Epoch 116\n",
      "------------------------------------\n",
      "Loss: 179.34945578540936\n",
      "Loss: 165.6411458534148\n",
      "Loss: 753.9542053211937\n",
      "Loss: 159.99776584083244\n",
      "Loss: 224.88980723013324\n",
      "Test Loss: 92.58030156793717\n",
      "Test Loss: 612.3377456290647\n",
      "Epoch 117\n",
      "------------------------------------\n",
      "Loss: 306.3072042317385\n",
      "Loss: 293.7219197970977\n",
      "Loss: 628.6348541191525\n",
      "Loss: 665.2410916165056\n",
      "Loss: 747.946460907987\n",
      "Test Loss: 408.1187678002018\n",
      "Test Loss: 0.039139887703889584\n",
      "Epoch 118\n",
      "------------------------------------\n",
      "Loss: 205.753732663221\n",
      "Loss: 128.64063639457538\n",
      "Loss: 115.15798212349789\n",
      "Loss: 376.60441296789816\n",
      "Loss: 3574.74096089291\n",
      "Test Loss: 183.56888566869594\n",
      "Test Loss: 2.3146152432965783\n",
      "Epoch 119\n",
      "------------------------------------\n",
      "Loss: 1844.0340093401765\n",
      "Loss: 1830.0724106945536\n",
      "Loss: 1841.824135736615\n",
      "Loss: 1474.0241898434933\n",
      "Loss: 953.8111512151684\n",
      "Test Loss: 242.6284302896235\n",
      "Test Loss: 24.463321286326362\n",
      "Epoch 120\n",
      "------------------------------------\n",
      "Loss: 875.1723106169266\n",
      "Loss: 1895.8697183912077\n",
      "Loss: 712.4545581199912\n",
      "Loss: 578.1857174045167\n",
      "Loss: 42.72933350334045\n",
      "Test Loss: 223.93324736098938\n",
      "Test Loss: 834.5464456501784\n",
      "Epoch 121\n",
      "------------------------------------\n",
      "Loss: 288.68150970457015\n",
      "Loss: 230.01054172939024\n",
      "Loss: 560.9321095174972\n",
      "Loss: 189.8262134052039\n",
      "Loss: 146.57249305043712\n",
      "Test Loss: 104.09026316394038\n",
      "Test Loss: 5.275535110321673\n",
      "Epoch 122\n",
      "------------------------------------\n",
      "Loss: 158.64051043012836\n",
      "Loss: 163.3508117169097\n",
      "Loss: 599.0147986587506\n",
      "Loss: 192.92583613194844\n",
      "Loss: 129.67183025151684\n",
      "Test Loss: 165.67656744236703\n",
      "Test Loss: 1.1609121344309599\n",
      "Epoch 123\n",
      "------------------------------------\n",
      "Loss: 100.67136636507394\n",
      "Loss: 141.59201507531097\n",
      "Loss: 393.31150033222934\n",
      "Loss: 408.6481475116567\n",
      "Loss: 102.35324021135663\n",
      "Test Loss: 91.81129460719092\n",
      "Test Loss: 27.33392795984444\n",
      "Epoch 124\n",
      "------------------------------------\n",
      "Loss: 356.58497251699055\n",
      "Loss: 378.3943647151796\n",
      "Loss: 199.20476569456113\n",
      "Loss: 240.4657152786355\n",
      "Loss: 27.822561961035355\n",
      "Test Loss: 87.73637972868511\n",
      "Test Loss: 0.2029614774299903\n",
      "Epoch 125\n",
      "------------------------------------\n",
      "Loss: 116.33090012946367\n",
      "Loss: 424.96220038319944\n",
      "Loss: 286.17669204811904\n",
      "Loss: 90.9142898766303\n",
      "Loss: 145.10568776388027\n",
      "Test Loss: 82.526824775089\n",
      "Test Loss: 282.63665051761086\n",
      "Epoch 126\n",
      "------------------------------------\n",
      "Loss: 180.5933103632471\n",
      "Loss: 85.7804710306029\n",
      "Loss: 123.84766281604193\n",
      "Loss: 262.471425558861\n",
      "Loss: 901.709998982534\n",
      "Test Loss: 71.49845735440411\n",
      "Test Loss: 0.004815789233792766\n",
      "Epoch 127\n",
      "------------------------------------\n",
      "Loss: 207.04450412614406\n",
      "Loss: 275.7027270670812\n",
      "Loss: 397.1740511407919\n",
      "Loss: 226.57111445262123\n",
      "Loss: 501.6715123453081\n",
      "Test Loss: 86.25590246394603\n",
      "Test Loss: 7.853457498477165\n",
      "Epoch 128\n",
      "------------------------------------\n",
      "Loss: 225.7378562756793\n",
      "Loss: 491.0663228807538\n",
      "Loss: 324.80170982064243\n",
      "Loss: 647.5116337760904\n",
      "Loss: 20.300706283876334\n",
      "Test Loss: 166.48434131759538\n",
      "Test Loss: 173.01983351831998\n",
      "Epoch 129\n",
      "------------------------------------\n",
      "Loss: 169.2151878718345\n",
      "Loss: 66.85298005262709\n",
      "Loss: 180.12762300815882\n",
      "Loss: 185.85152657481567\n",
      "Loss: 126.4520568106898\n",
      "Test Loss: 87.51725971797082\n",
      "Test Loss: 1.9295475832823428\n",
      "Epoch 130\n",
      "------------------------------------\n",
      "Loss: 128.51014026684268\n",
      "Loss: 135.00986080906276\n",
      "Loss: 118.10353282856818\n",
      "Loss: 238.6845281832711\n",
      "Loss: 103.83116898378191\n",
      "Test Loss: 93.95345841360488\n",
      "Test Loss: 21.30884964126523\n",
      "Epoch 131\n",
      "------------------------------------\n",
      "Loss: 281.58182198824795\n",
      "Loss: 66.40149835917859\n",
      "Loss: 117.1008495464185\n",
      "Loss: 221.77876835101677\n",
      "Loss: 35.33104758294582\n",
      "Test Loss: 73.55605070577437\n",
      "Test Loss: 242.7616764137988\n",
      "Epoch 132\n",
      "------------------------------------\n",
      "Loss: 170.27697586517274\n",
      "Loss: 136.9431453779952\n",
      "Loss: 260.65763965550303\n",
      "Loss: 196.09510753019924\n",
      "Loss: 34.825739059616325\n",
      "Test Loss: 120.58029719519755\n",
      "Test Loss: 0.7678860534586593\n",
      "Epoch 133\n",
      "------------------------------------\n",
      "Loss: 119.14684955790023\n",
      "Loss: 175.89697489994427\n",
      "Loss: 65.51871055955768\n",
      "Loss: 237.3385053589713\n",
      "Loss: 375.1188903095387\n",
      "Test Loss: 75.98657380838154\n",
      "Test Loss: 104.39780044029271\n",
      "Epoch 134\n",
      "------------------------------------\n",
      "Loss: 77.03529812964833\n",
      "Loss: 238.21615277895947\n",
      "Loss: 76.72943537231937\n",
      "Loss: 120.35022524582544\n",
      "Loss: 597.6748035941494\n",
      "Test Loss: 76.12160694985381\n",
      "Test Loss: 61.613481966914904\n",
      "Epoch 135\n",
      "------------------------------------\n",
      "Loss: 79.17507337219246\n",
      "Loss: 133.60446644461453\n",
      "Loss: 175.82490429815283\n",
      "Loss: 226.23643774216185\n",
      "Loss: 19.25975871752661\n",
      "Test Loss: 86.93782096451437\n",
      "Test Loss: 1.0559619094089607\n",
      "Epoch 136\n",
      "------------------------------------\n",
      "Loss: 89.5206333220209\n",
      "Loss: 167.69209098115974\n",
      "Loss: 190.69884134482135\n",
      "Loss: 123.90027873915317\n",
      "Loss: 6.136287653165647\n",
      "Test Loss: 80.16187824162793\n",
      "Test Loss: 5.298360767718296\n",
      "Epoch 137\n",
      "------------------------------------\n",
      "Loss: 162.09192141681845\n",
      "Loss: 124.24092662953466\n",
      "Loss: 186.87043390229573\n",
      "Loss: 71.8290035194012\n",
      "Loss: 2.5835463676759867\n",
      "Test Loss: 165.18108884999793\n",
      "Test Loss: 12.360345586325913\n",
      "Epoch 138\n",
      "------------------------------------\n",
      "Loss: 215.91522568226205\n",
      "Loss: 84.34208950764071\n",
      "Loss: 77.03074119733215\n",
      "Loss: 118.49410557477684\n",
      "Loss: 84.56013933201193\n",
      "Test Loss: 89.7211198497245\n",
      "Test Loss: 16.724195269892647\n",
      "Epoch 139\n",
      "------------------------------------\n",
      "Loss: 195.80946200420817\n",
      "Loss: 164.61777318074664\n",
      "Loss: 75.98762815859854\n",
      "Loss: 142.9125118786988\n",
      "Loss: 48.808606770012844\n",
      "Test Loss: 68.27148991434903\n",
      "Test Loss: 707.5270611935185\n",
      "Epoch 140\n",
      "------------------------------------\n",
      "Loss: 486.556009565659\n",
      "Loss: 559.851455927619\n",
      "Loss: 668.2354082671116\n",
      "Loss: 334.5375176836485\n",
      "Loss: 57.13710747549437\n",
      "Test Loss: 83.31756764442149\n",
      "Test Loss: 9.461803040500307\n",
      "Epoch 141\n",
      "------------------------------------\n",
      "Loss: 483.84716429927187\n",
      "Loss: 283.4754576880116\n",
      "Loss: 239.20612008411467\n",
      "Loss: 170.83380094585036\n",
      "Loss: 57.325723520299476\n",
      "Test Loss: 103.08588034057414\n",
      "Test Loss: 9.638935995162946\n",
      "Epoch 142\n",
      "------------------------------------\n",
      "Loss: 259.0707819162601\n",
      "Loss: 113.84307368644753\n",
      "Loss: 305.98678313144956\n",
      "Loss: 238.12897926336998\n",
      "Loss: 11.395029976026628\n",
      "Test Loss: 73.43606934447507\n",
      "Test Loss: 497.696187682829\n",
      "Epoch 143\n",
      "------------------------------------\n",
      "Loss: 138.02424966151744\n",
      "Loss: 125.2708005911406\n",
      "Loss: 63.929021584846495\n",
      "Loss: 285.8592493348765\n",
      "Loss: 58.97823510292529\n",
      "Test Loss: 161.6745677382398\n",
      "Test Loss: 1.593387568186372\n",
      "Epoch 144\n",
      "------------------------------------\n",
      "Loss: 132.1802411016861\n",
      "Loss: 98.06237304646066\n",
      "Loss: 267.43005912555105\n",
      "Loss: 87.50428323967324\n",
      "Loss: 138.8143842283813\n",
      "Test Loss: 75.79859382491574\n",
      "Test Loss: 163.19479460353384\n",
      "Epoch 145\n",
      "------------------------------------\n",
      "Loss: 294.79987372637635\n",
      "Loss: 180.70202090081736\n",
      "Loss: 64.7578773260121\n",
      "Loss: 112.1292757544861\n",
      "Loss: 76.81270897944891\n",
      "Test Loss: 60.47014597151516\n",
      "Test Loss: 279.1285000975585\n",
      "Epoch 146\n",
      "------------------------------------\n",
      "Loss: 152.6677126906562\n",
      "Loss: 93.7984013614389\n",
      "Loss: 284.9202899273453\n",
      "Loss: 465.19092040382765\n",
      "Loss: 173.67895013783144\n",
      "Test Loss: 106.93810593389905\n",
      "Test Loss: 381.3174826254128\n",
      "Epoch 147\n",
      "------------------------------------\n",
      "Loss: 180.22915787374797\n",
      "Loss: 448.00459398624616\n",
      "Loss: 430.865417418268\n",
      "Loss: 229.5441515213976\n",
      "Loss: 13.470966781375282\n",
      "Test Loss: 72.971196001146\n",
      "Test Loss: 508.5201451763965\n",
      "Epoch 148\n",
      "------------------------------------\n",
      "Loss: 209.0173221373918\n",
      "Loss: 261.6215779543385\n",
      "Loss: 379.5494633053743\n",
      "Loss: 940.8280594429987\n",
      "Loss: 134.32114517024746\n",
      "Test Loss: 332.2550224887055\n",
      "Test Loss: 280.82843950530076\n",
      "Epoch 149\n",
      "------------------------------------\n",
      "Loss: 125.0718691002467\n",
      "Loss: 232.8724407676496\n",
      "Loss: 467.6362566553886\n",
      "Loss: 341.7005057075566\n",
      "Loss: 978.701610763462\n",
      "Test Loss: 113.39666127977017\n",
      "Test Loss: 3.4376845148964095\n",
      "Epoch 150\n",
      "------------------------------------\n",
      "Loss: 216.74896528358778\n",
      "Loss: 272.4925107623476\n",
      "Loss: 462.21838593302755\n",
      "Loss: 290.6986765248622\n",
      "Loss: 647.59470351797\n",
      "Test Loss: 193.73860176563477\n",
      "Test Loss: 0.050242617019823826\n",
      "Training complete!\n",
      "tensor(0.3250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n------------------------------------\")\n",
    "    train_loop(LFW_train, model, LOSS_FUNCTION, optimizer, LOWEST_LOSS)\n",
    "    test_loop(LFW_test, model, LOSS_FUNCTION, optimizer, LOWEST_LOSS)\n",
    "    X_epochs.append(t)\n",
    "print(\"Training complete!\")\n",
    "print(LOWEST_LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1711.4879924052043, 501747.07980719674, 28954.63832118937, 31116.65455842917, 145799.41497881425, 11355.929042035592, 2574.9661570387616, 500.58914448699056, 6710.133269233986, 34968.19503746668, 6401.598192191775, 10714.484029238389, 9744.452382591795, 7695.320618955872, 3275.539951228861, 1684.4508921855304, 4208.304166888015, 2132.709536990068, 6784.584193680972, 76.87927675183187, 1490.3553034534548, 3275.2201663759365, 3386.962875456083, 1637.8689217176602, 463.8694005032329, 5176.703781302061, 4205.738727577913, 420.91428824772026, 175.00508194621514, 149.14938539386074, 1068.9073052873964, 466.15274555447274, 602.6211055280907, 295.61350327602315, 73.69530635228436, 251.56334158354497, 2939.147659828135, 269.8113970641512, 273.62810207290516, 400.51177240523293, 434.0862610778142, 572.8576091273857, 487.6936340302028, 725.0442799275309, 176.8350808648991, 830.2677475020918, 304.5293033456086, 1146.9517998058216, 210.2099358236257, 816.8860761455055, 131.31994623858523, 311.35783789411835, 1444.982136560503, 279.71304656647254, 949.7645615675631, 667.5739073898233, 104.13571927894459, 407.67405091866783, 685.0576593447789, 116.7968295676549, 251.7256664396461, 485.16813113198475, 768.57558173097, 319.35359381150937, 155.9521818888434, 202.03437756335893, 595.0737983947138, 628.7726722260968, 221.55116348600336, 51.0467621383992, 175.808305406785, 102.16399436068244, 833.7025867064889, 441.20053795406153, 1180.8685791161965, 170.74825892168136, 1503.78229636149, 242.27572254392126, 216.70191552735548, 220.0494306959756, 111.80294350723716, 276.24325187208393, 1066.7242502622737, 173.22989046877314, 89.2524226155666, 588.2512059102801, 395.42834740281154, 129.40846200651677, 132.75580707323311, 408.1476146421577, 322.47743588530477, 406.2889028964734, 279.3250170841449, 124.08175555882018, 161.52473862778555, 658.0535609444478, 184.9802130206108, 438.7692503001846, 222.51165686434143, 422.90415062836996, 288.07941081365664, 861.7870927733195, 364.5394525081226, 337.1768204033868, 114.77817611216193, 360.2385311282416, 366.700311665604, 700.0428450588524, 187.07586805340804, 19.96343072000645, 108.7888918868754, 511.38921320438664, 434.25811617817465, 254.433438814527, 936.6269783897252, 357.55002444854046, 1272.7080837416697, 229.5416711139224, 292.90178498018736, 25.62041724051129, 718.8887067968943, 233.57860760463979, 408.8094768886782, 1051.5003143959111, 4.171635883027919, 1137.3793563906258, 242.68923615012727, 294.58561231418196, 338.8460300577187, 215.74402613638895, 355.43942200841263, 805.0486706409238, 972.1630773725112, 2663.3402813344414, 543.4708888654607, 341.619933558021, 187.77182796219023, 752.7454234710203, 1173.4529108885492, 214.9355379513254, 240.04678359390394, 199.34575454207612, 443.9559165630207, 448.3481497345224, 156.09164435651286, 228.64181844328724, 218.6896716896744, 318.0726040938562, 340.84651532353877, 376.9810449218959, 195.1239533434204, 308.0993443596559, 250.46515333478203, 143.036388939833, 24.98208142405299, 373.91230895432136, 182.65128798817824, 154.38544328926918, 348.2811756113206, 1215.2210103213122, 358.27685360747955, 178.22229630758676, 214.06674840388058, 392.76089088929655, 50.86012832288896, 281.09832599611536, 238.87903572901388, 282.0305220286195, 143.44848647631002, 163.3993782384553, 382.99647548877033, 142.45540812072508, 73.74836314065868, 182.73556061556246, 497.8660471428176, 228.0460582387243, 243.99591354292824, 756.9122502210046, 480.98576194623604, 191.53066022921897, 463.35517197232366, 710.591500601022, 650.4730351431934, 92.15200958067649, 99.67301054454005, 390.0341363656411, 1071.6459773184638, 384.9543428986722, 180.81980226665422, 1339.4797025070875, 488.6677171272452, 99.6875060527473, 188.76950634626957, 195.76724930118942, 513.3065648246678, 119.84096358593985, 284.90622911073507, 339.06350969419, 125.12693340562686, 141.5106614209639, 183.7160835559842, 245.65562272782265, 228.50606205160796, 223.51080968116483, 149.12585669190784, 180.22503970876193, 81.44125827859932, 218.78170188835853, 246.83593283936546, 101.61118264661076, 294.58488418333974, 156.82852107057045, 222.72977994304182, 201.95341561504378, 12.77614627238256, 79.49023188564269, 182.50692432473681, 179.47637125578908, 231.75502774890913, 15.641851590652735, 215.7396633453642, 217.39863250739864, 109.28499982549852, 70.78151027631588, 99.56894480055273, 160.17439439013478, 168.13784680557683, 79.60916537038787, 240.381036667805, 54.77363496023515, 135.52251544832643, 162.2965293846279, 206.87727016805974, 73.00800218055497, 40.49807327499215, 304.4849623950208, 411.9649148015212, 294.6060793923252, 165.20659629720296, 393.4609964010852, 382.85031055712693, 151.8501035595644, 258.51234227102987, 80.31183959190402, 923.1808641483899, 548.1272567238427, 557.569134993875, 181.55488280490806, 348.80440622253354, 79.19909803414073, 927.6855614048991, 813.9080956130986, 365.4169582303728, 69.70481063474281, 33.54402902661403, 1108.9585419741877, 456.5271538262509, 488.49325679768657, 77.07592639545565, 1246.6821791928473, 485.3000483419361, 105.27104182036064, 288.7388567964265, 122.2690229099179, 20.80645374781902, 271.1398138144028, 452.54372551032975, 154.9548054042681, 219.35554322311765, 222.26207629624446, 302.50587366813664, 69.78120018578413, 188.67932251649833, 169.0226601177917, 730.1840445338307, 161.0288073764653, 93.30206324457843, 160.34023768083682, 263.3447555540752, 1.2050213585328178, 320.41273469163343, 261.64242844350986, 347.46068223268014, 271.18406355005106, 74.34500210957779, 370.2698007373393, 243.2833639542544, 430.7379411296844, 169.11038519311705, 26.94497464268757, 379.5248662530563, 176.7508404148004, 451.9936910373801, 123.98759172802737, 122.70754028752714, 176.96933012041984, 255.60178652379506, 253.3291661637782, 165.8503506954678, 315.45658567682483, 225.90637894636603, 164.79485100527592, 394.56074705418473, 240.58851493366595, 125.31408134525435, 251.18968455144974, 229.32982035450982, 193.15107200908295, 148.68337231089635, 72.25475949278268, 251.86837521763516, 143.73355012236811, 179.19511498487486, 169.5802426743114, 223.5014895128823, 202.37746616340118, 137.41819998474574, 374.10316306777577, 195.24968927871964, 38.55520757962219, 292.33057474521365, 251.69420281721344, 154.71739024454862, 170.28824584534595, 275.9590757752267, 165.40919623747783, 208.55625686353687, 284.7537858482041, 147.13499004704397, 26.60446836804433, 538.3184171509042, 311.8877548873106, 205.929309670637, 93.00315019598835, 119.95208003691697, 163.43495132019336, 253.31794820184518, 195.0709847718763, 223.86670750170373, 373.8735090520445, 261.0350514956107, 68.62411898059632, 139.03828742597497, 84.92056344269616, 15.916620558861595, 96.88428636397308, 308.1011542668017, 195.46133455186185, 170.71923959586456, 139.10649457193827, 258.1357655693899, 316.5144159295649, 177.68871538213517, 102.57014746448172, 333.65262996170105, 150.8395816454223, 133.78956884614442, 99.41660440768507, 172.71544376051804, 64.31288424014323, 120.49857875636454, 182.89819363549057, 64.03918287309979, 203.88411168014144, 144.5253750524036, 101.11329020772033, 87.66821221922307, 90.652778143321, 204.2142796787903, 513.312277791179, 213.4595957386359, 284.69852308354353, 417.12961785703703, 227.76388462840976, 8.345182809472377, 437.4622251014127, 174.19152646519825, 75.57784009627773, 206.3935699720324, 147.4403828081774, 110.51270283895998, 896.8047512439342, 1697.847391068105, 517.3686935426564, 1301.0253645253526, 104.76688981057207, 769.4738867525712, 200.84584868946422, 182.60700026671176, 1.2553201355578734, 293.31927531853614, 98.92141722168527, 126.20484070563981, 299.4004636381008, 102.90137395329499, 240.12059061304547, 459.8906675450896, 198.62546857124718, 282.7998426534158, 90.7176874088697, 140.62424875926584, 168.72264205840787, 106.70922099880018, 194.7779866175281, 119.36420973588935, 155.53972047541632, 154.43195306492566, 204.96465205630545, 102.46805371893613, 58.49434837247612, 100.93467099985995, 131.9928410973144, 155.66381814809654, 242.96412830942765, 200.32623154872917, 265.30891238703924, 112.00676098251661, 247.8162141117853, 167.61735098684102, 4.700280184934947, 127.9876380446177, 364.93177685287606, 149.85786064589973, 58.07353418169738, 56.12416744639347, 132.33640976675068, 218.33319414261996, 240.95764081880492, 114.3194512696198, 173.13368107852693, 211.23947700703394, 131.72589406227, 105.53843326581796, 191.27334623288505, 323.36396450609794, 124.84721844820339, 159.1482857692135, 71.1644608711697, 153.0683520674261, 169.80794682387003, 290.29291351578553, 82.48839856072274, 145.041810281003, 86.50841888126688, 48.46570520703136, 106.12559986771562, 105.36785096886821, 184.81712863854867, 329.40751898318297, 82.55392586728837, 271.9166682300315, 158.6605046124413, 176.83185640760732, 129.42345360596786, 8.18248880149687, 86.39673532944146, 145.91546220955473, 142.92301445453305, 140.2990749859668, 453.57009179632234, 131.1448043202728, 170.91210709898598, 44.15716085585703, 249.2649752666683, 331.8297095966035, 180.5445762485487, 151.77163392967114, 364.5446843499205, 60.39374428956841, 54.58376437223849, 445.94545644003665, 309.5351310867815, 158.21878042309314, 58.01676593246634, 142.63417457487188, 284.48120900812273, 204.98616258082518, 68.36499734095695, 103.39855496961079, 97.29713286273139, 286.9761347652342, 84.98399155734194, 61.172278355976076, 278.1737285844993, 265.1505223511766, 116.46034859259949, 114.97679261263086, 98.12037225402814, 129.89345552360737, 268.4899070325085, 163.1472150897116, 105.97459435254585, 183.29845921872882, 125.91576858418203, 0.49340469087445865, 123.68655946117774, 158.00809131187404, 62.95297829134619, 100.95320198525505, 9.599001421915927, 76.66384308908042, 190.5996360211766, 222.2061539804992, 123.44498366368637, 1.3130329720588865, 43.338348150941606, 164.53022775563738, 197.23958783800063, 231.2419778067999, 217.51704965738344, 183.07839569683176, 400.0337275064336, 159.09940842143425, 93.60344086962591, 3.380387866988487, 300.8593048079928, 147.3508853306345, 110.69323016866034, 103.87694509185717, 736.6392450828268, 88.96699418689794, 173.30040971661253, 237.82018614002672, 80.36695807449468, 137.39583756885833, 217.58333266438805, 107.33794549229701, 85.06118041304093, 84.42781500932969, 0.4062681349246535, 164.8979877371097, 64.28778950429624, 54.99231289874375, 133.47924700463224, 107.31732063923309, 81.44026170908084, 100.56900927071953, 137.50260427425815, 61.64062624669515, 29.781442709210324, 133.38089567416114, 97.36608588862913, 41.28331130510714, 103.88536156714756, 54.98425641310298, 151.6983530869636, 126.02468361640773, 43.24290457817025, 115.62605146384182, 25.702080857889545, 172.4518826756222, 90.4271620230044, 112.57263986947558, 90.60836350297282, 78.97737655808804, 139.98148601256264, 154.1561268548945, 117.83887222420775, 59.13228742674777, 320.27050394426703, 156.74347344872285, 117.24295334207066, 114.56529956480068, 86.87931496351389, 0.3250426988327381, 301.95165459718663, 739.7835763798369, 1410.1700502404874, 192.5745578196204, 178.8931001858324, 46.372795164941216, 699.5215513003825, 1126.246680527411, 999.8673767794787, 352.97474824785445, 179.34945578540936, 165.6411458534148, 753.9542053211937, 159.99776584083244, 224.88980723013324, 306.3072042317385, 293.7219197970977, 628.6348541191525, 665.2410916165056, 747.946460907987, 205.753732663221, 128.64063639457538, 115.15798212349789, 376.60441296789816, 3574.74096089291, 1844.0340093401765, 1830.0724106945536, 1841.824135736615, 1474.0241898434933, 953.8111512151684, 875.1723106169266, 1895.8697183912077, 712.4545581199912, 578.1857174045167, 42.72933350334045, 288.68150970457015, 230.01054172939024, 560.9321095174972, 189.8262134052039, 146.57249305043712, 158.64051043012836, 163.3508117169097, 599.0147986587506, 192.92583613194844, 129.67183025151684, 100.67136636507394, 141.59201507531097, 393.31150033222934, 408.6481475116567, 102.35324021135663, 356.58497251699055, 378.3943647151796, 199.20476569456113, 240.4657152786355, 27.822561961035355, 116.33090012946367, 424.96220038319944, 286.17669204811904, 90.9142898766303, 145.10568776388027, 180.5933103632471, 85.7804710306029, 123.84766281604193, 262.471425558861, 901.709998982534, 207.04450412614406, 275.7027270670812, 397.1740511407919, 226.57111445262123, 501.6715123453081, 225.7378562756793, 491.0663228807538, 324.80170982064243, 647.5116337760904, 20.300706283876334, 169.2151878718345, 66.85298005262709, 180.12762300815882, 185.85152657481567, 126.4520568106898, 128.51014026684268, 135.00986080906276, 118.10353282856818, 238.6845281832711, 103.83116898378191, 281.58182198824795, 66.40149835917859, 117.1008495464185, 221.77876835101677, 35.33104758294582, 170.27697586517274, 136.9431453779952, 260.65763965550303, 196.09510753019924, 34.825739059616325, 119.14684955790023, 175.89697489994427, 65.51871055955768, 237.3385053589713, 375.1188903095387, 77.03529812964833, 238.21615277895947, 76.72943537231937, 120.35022524582544, 597.6748035941494, 79.17507337219246, 133.60446644461453, 175.82490429815283, 226.23643774216185, 19.25975871752661, 89.5206333220209, 167.69209098115974, 190.69884134482135, 123.90027873915317, 6.136287653165647, 162.09192141681845, 124.24092662953466, 186.87043390229573, 71.8290035194012, 2.5835463676759867, 215.91522568226205, 84.34208950764071, 77.03074119733215, 118.49410557477684, 84.56013933201193, 195.80946200420817, 164.61777318074664, 75.98762815859854, 142.9125118786988, 48.808606770012844, 486.556009565659, 559.851455927619, 668.2354082671116, 334.5375176836485, 57.13710747549437, 483.84716429927187, 283.4754576880116, 239.20612008411467, 170.83380094585036, 57.325723520299476, 259.0707819162601, 113.84307368644753, 305.98678313144956, 238.12897926336998, 11.395029976026628, 138.02424966151744, 125.2708005911406, 63.929021584846495, 285.8592493348765, 58.97823510292529, 132.1802411016861, 98.06237304646066, 267.43005912555105, 87.50428323967324, 138.8143842283813, 294.79987372637635, 180.70202090081736, 64.7578773260121, 112.1292757544861, 76.81270897944891, 152.6677126906562, 93.7984013614389, 284.9202899273453, 465.19092040382765, 173.67895013783144, 180.22915787374797, 448.00459398624616, 430.865417418268, 229.5441515213976, 13.470966781375282, 209.0173221373918, 261.6215779543385, 379.5494633053743, 940.8280594429987, 134.32114517024746, 125.0718691002467, 232.8724407676496, 467.6362566553886, 341.7005057075566, 978.701610763462, 216.74896528358778, 272.4925107623476, 462.21838593302755, 290.6986765248622, 647.59470351797]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_loss['train'])\n",
    "plt.plot(y_loss['train'])\n",
    "plt.plot(y_loss['test'])\n",
    "#plt.plot(X_epochs)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05dbbb7414389032baa654308b5b2368ed4754b5c0531661864b7939633c6eac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
